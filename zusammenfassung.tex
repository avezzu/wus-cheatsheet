\documentclass[10pt,landscape]{article}
\usepackage{multicol}
\usepackage{calc}
\usepackage{ifthen}
\usepackage[landscape]{geometry}
\usepackage{hyperref}

\usepackage[OT1]{fontenc}
\usepackage[sc]{mathpazo}
\usepackage[utf8]{inputenc}
\usepackage[german]{babel}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{mathtools}
\usepackage{fancyhdr}
\usepackage{setspace}
\usepackage{listings}
\usepackage{stmaryrd}
\usepackage{graphicx}
\usepackage{changepage}
\usepackage{enumitem}
\usepackage{wrapfig}
\usepackage{tikz} 
\usepackage{xcolor, soul}
\newcommand{\green}[1]{\sethlcolor{green}\hl{#1}}
\newcommand{\yellow}[1]{\sethlcolor{yellow} \hl{#1}}
\newcommand{\blue}[1]{\sethlcolor{cyan} \hl{#1}}


% To make this come out properly in landscape mode, do one of the following
% 1.
%  pdflatex latexsheet.tex
%
% 2.
%  latex latexsheet.tex
%  dvips -P pdf  -t landscape latexsheet.dvi
%  ps2pdf latexsheet.ps


% If you're reading this, be prepared for confusion.  Making this was
% a learning experience for me, and it shows.  Much of the placement
% was hacked in; if you make it better, let me know...


% 2008-04
% Changed page margin code to use the geometry package. Also added code for
% conditional page margins, depending on paper size. Thanks to Uwe Ziegenhagen
% for the suggestions.

% 2006-08
% Made changes based on suggestions from Gene Cooperman. <gene at ccs.neu.edu>


% To Do:
% \listoffigures \listoftables
% \setcounter{secnumdepth}{0}


% This sets page margins to .5 inch if using letter paper, and to 1cm
% if using A4 paper. (This probably isn't strictly necessary.)
% If using another size paper, use default 1cm margins.
\ifthenelse{\lengthtest { \paperwidth = 11in}}
	{ \geometry{top=.5in,left=.5in,right=.5in,bottom=.5in} }
	{\ifthenelse{ \lengthtest{ \paperwidth = 297mm}}
		{\geometry{top=1cm,left=1cm,right=1cm,bottom=1cm} }
		{\geometry{top=1cm,left=1cm,right=1cm,bottom=1cm} }
	}

% Turn off header and footer
\setcounter{page}{1}


% Redefine subsection commands to use less space
\makeatletter
\renewcommand{\subsection}{\@startsection{subsection}{1}{0mm}%
                                {-1ex plus -.5ex minus -.2ex}%
                                {0.5ex plus .2ex}%x
                                {\normalfont\large\bfseries}}
\renewcommand{\subsection}{\@startsection{subsection}{2}{0mm}%
                                {-1explus -.5ex minus -.2ex}%
                                {0.5ex plus .2ex}%
                                {\normalfont\normalsize\bfseries}}
\renewcommand{\subsubsection}{\@startsection{subsubsection}{3}{0mm}%
                                {-1ex plus -.5ex minus -.2ex}%
                                {1ex plus .2ex}%
                                {\normalfont\small\bfseries}}
\makeatother

% Define BibTeX command
\def\BibTeX{{\rm B\kern-.05em{\sc i\kern-.025em b}\kern-.08em
    T\kern-.1667em\lower.7ex\hbox{E}\kern-.125emX}}

% Don't print subsection numbers
\setcounter{secnumdepth}{0}


\setlength{\parindent}{0pt}
\setlength{\parskip}{0pt plus 0.5ex}


% -----------------------------------------------------------------------

\begin{document}
\raggedright
\footnotesize
\begin{multicols}{3}


% multicol parameters
% These lengths are set only within the two main columns
%\setlength{\columnseprule}{0.25pt}
\setlength{\premulticols}{1pt}
\setlength{\postmulticols}{1pt}
\setlength{\multicolsep}{1pt}
\setlength{\columnsep}{2pt}

\begin{center}
     \Large{\textbf{WuS - Cheatsheet}} \\
\end{center}
\section{Wahrscheinlichkeitsräume}
\subsection{Grundraum}
\blue{Terminologie:} Die Menge $\Omega$ nennen wir Grundraum. 
\subsection{Ereignisse}
Ein Element $\omega \in \Omega$ nennen wir Elementarereignis (oder Ausgang des Experiments).\\
\blue{Definition 1.1:} Ein Mengensystem $\mathcal{F} \subset \mathcal{P}(\Omega)$ heisst Sigma-Algebra ( $\sigma$-Algebra), falls es die folgenden Eigenschaften erfüllt
\begin{enumerate}
    \item $\Omega \in \mathcal{F}$
    \item $A \in \mathcal{F} \Rightarrow A^{c} \in \mathcal{F}$ 
    \item $A_{1}, A_{2}, \ldots \in \mathcal{F} \Rightarrow \bigcup_{i=1}^{\infty} A_{i} \in \mathcal{F}$
\end{enumerate}
Dabei nennen wir die Elemente der $\sigma$-Algebra Ereignisse.\\
\subsection{Wahrscheinlichkeitsmass}
\blue{Definition 1.2:} Sei $\Omega$ ein Grundraum und sei $\mathcal{F}$ eine $\sigma$-Algebra. Eine Abbildung
$$
\begin{aligned}
\mathbb{P}: \mathcal{F} & \rightarrow[0,1] \\
A & \mapsto \mathbb{P}[A]
\end{aligned}
$$
heisst Wahrscheinlichkeitsmass auf $(\Omega, \mathcal{F})$, falls folgende Eigenschaften gelten
\begin{enumerate}
    \item $\mathbb{P}[\Omega]=1$.
    \item ( $\sigma$-Additivität) $\mathbb{P}[A]=\sum_{i=1}^{\infty} \mathbb{P}\left[A_{i}\right] \quad$ if $A=\bigcup_{i=1}^{\infty} A_{i}$ (disjunkte Vereinigung).
\end{enumerate}
\subsection{Der Wahrscheinlichkeitsraum} 
\blue{Definition 1.3:} Sei $\Omega$ ein Grundraum, $\mathcal{F}$ eine $\sigma$-Algebra, und $\mathbb{P}$ ein Wahrscheinlichkeitsmass. Wir nennen das Tripel $(\Omega, \mathcal{F}, \mathbb{P})$ Wahrscheinlichkeitsraum.\\
\textbf{Bemerkung 1.4:} Das Ereignis $A=\varnothing$ tritt niemals ein. Das Ereignis $A=\Omega$ tritt stets ein.\\
\blue{Definition 1.5:} Sei $\Omega$ eine endlicher Grundraum. Das Laplace Modell auf $\Omega$ ist ein Tripel $(\Omega, \mathcal{F}, \mathbb{P})$, sodass
\begin{enumerate}
    \item $\mathcal{F}=\mathcal{P}(\Omega)$,
    \item  $\mathbb{P}: \mathcal{F} \rightarrow[0,1]$ ist definiert durch
    $$
    \forall A \in \mathcal{F} \quad \mathbb{P}[A]=\frac{|A|}{|\Omega|} .
    $$
\end{enumerate}
\subsection{Eigenschaften von Ereignissen}
\yellow{Satz 1.6 (Abgeschlossenheit der $\sigma$-Algebra bzgl. Operationen):} Sei $\mathcal{F}$ eine $\sigma$-Algebra auf $\Omega$. Es gilt
\begin{enumerate}
    \item $\varnothing \in \mathcal{F}$,
    \item $A_{1}, A_{2}, \ldots \in \mathcal{F} \Rightarrow \bigcap_{i=1}^{\infty} A_{i} \in \mathcal{F}$,
    \item $A, B \in \mathcal{F} \Rightarrow A \cup B \in \mathcal{F}$,
    \item $A, B \in \mathcal{F} \Rightarrow A \cap B \in \mathcal{F}$.
\end{enumerate}
\includegraphics[width = 0.3\textwidth]{prob_interpr_sets.png}
\textbf{Beziehung/Interpretationen zwischen Ereignissen}
\includegraphics[width = 0.3\textwidth]{prob_interpr_two_events.png}
\subsection{Eigenschaften von Wahrscheinlichkeitsmassen}
\yellow{Satz 1.7:} Sei $\mathbb{P}$ ein Wahrscheinlichkeitsmass auf $(\Omega, \mathcal{F})$. Es gilt:
\begin{enumerate}
    \item $\mathbb{P}[\varnothing]=0$
    \item (Additivität) Sei $k \geq 1$, seien $A_{1}, \ldots, A_{k}$-viele paarweise disjunkte Ereignisse, dann gilt 
    $$
    \mathbb{P}\left[A_{1} \cup \cdots \cup A_{k}\right]=\mathbb{P}\left[A_{1}\right]+\cdots+\mathbb{P}\left[A_{k}\right]
    $$
    \item Sei $A$ ein Ereignis, dann gilt $\mathbb{P}\left[A^{c}\right]=1-\mathbb{P}[A]$
    \item Falls $A$ und $B$ zwei (nicht notwendigerweise disjunkte) Ereignisse, dann gilt 
    $$
    \mathbb{P}[A \cup B]=\mathbb{P}[A]+\mathbb{P}[B]-\mathbb{P}[A \cap B]
    $$
\end{enumerate}
\subsection{Nützliche Ungleichungen}
\yellow{Satz $1.8$ (Monotonie):} Seien $A, B \in \mathcal{F}$, dann gilt $A \subset B \Rightarrow \mathbb{P}[A] \leq \mathbb{P}[B].$\\
\yellow{Satz $1.9$ (Union Bound):} Sei $A_{1}, A_{2}, \ldots$ eine Folge von (nicht notwendigerweise disjunkten) Ereignissen, dann gilt die folgende Ungleichung
$\mathbb{P}\left[\bigcup_{i=1}^{\infty} A_{i}\right] \leq \sum_{i=1}^{\infty} \mathbb{P}\left[A_{i}\right]$.\\
\textbf{Bemerkung 1.10:} Die obrige Ungleichung gilt ebenfalls für eine Folge von endlich vielen nicht-leeren Ereignissen.
\subsection{Stetigkeit von Wahrscheinlichkeitsmassen}
\yellow{Satz 1.11:} Sei $\left(A_{n}\right)$ eine monoton wachsende Folge von Ereignissen $\left(\forall n: A_{n} \subset A_{n+1}\right).$ Dann gilt
$$
\lim _{n \rightarrow \infty} P\left[A_{n}\right]=\mathbb{P}\left[\bigcup^{\infty} A_{n}\right] . \quad \text { monoton wachsender Grenzwert }
$$
Sei $\left(B_{n}\right)$ eine monoton fallende Folge von Ereignissen $\forall n: \left(B_{n} \supset B_{n+1}\right).$ Dann gilt
$$
\lim _{n \rightarrow \infty} P\left[B_{n}\right]=\mathbb{P}\left[\bigcap_{n=1}^{\infty} B_{n}\right] . \quad \text { monoton fallender Grenzwert }
$$.\\
\textbf{Bemerkung 1.12:} Durch Monotonie erhalten wir $\mathbb{P}\left[A_{n}\right] \leq \mathbb{P}\left[A_{n+1}\right]$ und $\mathbb{P}\left[B_{n}\right] \geq \mathbb{P}\left[B_{n+1}\right]$ für jedes n. 
Daher sind die Grenzwerte in den obrigen Gleichungen wohldefiniert.
\subsection{Bedingte Wahrscheinlichkeit}
\blue{Definition $1.13$ (Bedingte Wahrscheinlichkeit):} Sei $(\Omega, \mathcal{F}, \mathbb{P})$ ein Wahrscheinlichkeitsraum. Seien $A, B$ zwei Ereignisse mit $\mathbb{P}[B]>0$. Wir definieren die bedingte Wahrscheinlichkeit von $A$ gegeben $B$ wie folgt
$$
\mathbb{P}[A \mid B]=\frac{\mathbb{P}[A \cap B]}{\mathbb{P}[B]} .
$$\\
\textbf{Bemerkung 1.14:} $\mathbb{P}[B \mid B]=1$.\\
\yellow{Satz 1.15:} Sei $(\Omega, \mathcal{F}, \mathbb{P})$ ein Wahrscheinlichkeitsraum. Sei $B$ ein Ereignis mit positiver Wahrscheinlichkeit. 
Dann ist $\mathbb{P}[. \mid B]$ ein $W$-Mass auf $\Omega$.\\
\yellow{Satz $1.16$ (Gesetz der totalen Wahrscheinlichkeit):} Sei $B_{1}, \cdots, B_{n}$ $\text{eine Partition}^{a}$ des Grundraums $\Omega$, so dass $\mathbb{P}\left[B_{i}\right]>0$ für jedes $1 \leq i \leq n$ gilt. Dann gilt
$$
\forall A \in \mathcal{F} \quad \mathbb{P}[A]=\sum_{i=1}^{n} \mathbb{P}\left[A \mid B_{i}\right] \mathbb{P}\left[B_{i}\right]
$$
$a_{\text{i.e. }} \Omega=B_{1} \cup \cdots \cup B_{n}$ mit paarweise disjunkten Ereignissen. \\
\yellow{Satz $1.17$ (Satz von Bayes):} Sei $B_{1}, \ldots, B_{n} \in \mathcal{F}$ eine Partition von $\Omega$ sodass, $\mathbb{P}\left[B_{i}\right]>0$ für jedes $i$ gilt. Für jedes Ereignis $A$ mit $\mathbb{P}[A]>0$ gilt
$$
\forall i=1, \ldots, n \quad \mathbb{P}\left[B_{i} \mid A\right]=\frac{\mathbb{P}\left[A \mid B_{i}\right] \mathbb{P}\left[B_{i}\right]}{\sum_{j=1}^{n} \mathbb{P}\left[A \mid B_{j}\right] \mathbb{P}\left[B_{j}\right]}
$$\\
\textbf{Bemerkung:} Eine Folgerung davon ist $\mathbb{P}[A|B] = \frac{\mathbb{P}[B|A]\cdot \mathbb{P}[A]}{\mathbb{P}[B]}$\\
\subsection{Unabhängigkeit von Ereignissen}
\blue{Definition 1.18 (Unabh{\"a}ngigkeit):} Sei $(\Omega, \mathcal{F}, \mathbb{P})$ ein Wahrscheinlichkeitsraum. Zwei Ereignisse $A$ und $B$ heissen unabhängig falls
$\mathbb{P}[A \cap B]=\mathbb{P}[A] \mathbb{P}[B].$\\
\textbf{Bemerkung 1.19.} Falls $\mathbb{P}[A] \in\{0,1\}$, dann ist A unabhängig von jedem Ereignis sodass,
$$
\forall B \in \mathcal{F} \quad \mathbb{P}[A \cap B]=\mathbb{P}[A] \mathbb{P}[B] .
$$
Falls ein Ereignis $A$ unabhängig von sich selbst ist, also $\left.\mathbb{P}[A \cap A]=\mathbb{P}[A]^{2}\right)$ gilt, dann muss $\mathbb{P}[A] \in\{0,1\}$ gelten.
$A$ ist unabhängig von $B$ genau dann wenn $A$ unabhängig von $B^{c}$ ist.\\
\yellow{Satz 1.20:} Seien $A, B \in \mathcal{F}$ zwei Ereignisse mit $\mathbb{P}[A], \mathbb{P}[B]>0$. Dann sind folgende Aussagen äquivalent:
\begin{enumerate}
    \item $\mathbb{P}[A \cap B]=\mathbb{P}[A] \mathbb{P}[B]$, $A$ und $B$ sind unabhängig
    \item $\mathbb{P}[A \mid B]=\mathbb{P}[A]$, Eintreten von $B$ hat keinen Einfluss auf $A$
    \item $\mathbb{P}[B \mid A]=\mathbb{P}[B]$. Eintreten von $A$ hat keinen Einfluss auf $B$
\end{enumerate}
\blue{Definition 1.21:} Sei $I$ eine beliebe Indexmenge. Eine Familie von Ereignissen $\left(A_{i}\right)_{i \in I}$ heisst unabhängig falls
$$
\forall J \subset I \text { endlich } \mathbb{P}\left[\bigcap_{j \in J} A_{j}\right]=\prod_{j \in J} \mathbb{P}\left[A_{j}\right] \text {. }
$$\\
\textbf{Bemerkung:} Drei Ereignisse $A, B$ und $C$ sind unabhängig falls alle 4 folgenden Gleichungen erfüllt sind (nicht nur die Letzte!):
$$
\begin{aligned}
\mathbb{P}[A \cap B] &=\mathbb{P}[A] \mathbb{P}[B], \\
\mathbb{P}[A \cap C] &=\mathbb{P}[A] \mathbb{P}[C], \\
\mathbb{P}[B \cap C] &=\mathbb{P}[B] \mathbb{P}[C], \\
\mathbb{P}[A \cap B \cap C] &=\mathbb{P}[A] \mathbb{P}[B] \mathbb{P}[C]
\end{aligned}
$$\\
\section{Zufallsvariablen und Verteilungsfunktionen}
\subsection{Abstrakte Definition}
\blue{Definition 2.1:} Sei $(\Omega, \mathcal{F}, \mathbb{P})$ ein Wahrscheinlichkeitsraum. Eine Zufallsvariable (Z.V.) ist eine Abbildung $X: \Omega \rightarrow \mathbb{R}$ sodass, für alle $a \in \mathbb{R}$ gilt,
$$
\{\omega \in \Omega: X(\omega) \leq a\} \in \mathcal{F} .
$$\\
\blue{Indikatorfunktion:} Sei $A \in \mathcal{F}$. Wir definieren die Indikatorfunktion $\mathbb{1}_{A}$ auf $A$, durch
$$
\forall \omega \in \Omega \quad \mathbb{1}_{A}(\omega)= \begin{cases}0 & \text { if } \omega \notin A, \\ 1 & \text { if } \omega \in A .\end{cases}
$$.\\
\textbf{Notation:} Für Ereignisse im Bezug auf Z.V. werden wir auf darauf verzichten sie mittels Beziehung zu $\omega$ darzustellen. Stattdessen schreiben wir für $a \leq b$
$$
\begin{aligned}
&\{X \leq a\}=\{\omega \in \Omega: X(\omega) \leq a\} \\
&\{a<X \leq b\}=\{\omega \in \Omega: a<X(\omega)<b\}, \\
&\{X \in \mathbb{Z}\}=\{\omega \in \Omega: X(\omega) \in \mathbb{Z}\}
\end{aligned}
$$
Betrachten wir die Wahrscheinlichkeit nach obigen Beispiel. Dann lassen wir gerade die Klammern weg und schreiben einfach
$$
\mathbb{P}[X \leq a]=\mathbb{P}[\{X \leq a\}]=\mathbb{P}[\{\omega \in \Omega: X(\omega) \leq a\}] .
$$
\subsection{Verteilungsfunktion}
\blue{Definition 2.2:} Sei $X$ eine Zufallsvariable auf einem $W$-Raum $(\Omega, \mathcal{F}, \mathbb{P})$. Die Verteilungsfunktion von $X$ ist eine Funktion $F_{X}: \mathbb{R} \rightarrow[0,1]$, definiert durch
$$
\forall a \in \mathbb{R} \quad F_{X}(a)=\mathbb{P}[X \leq a] .
$$\\
\textbf{Example 2:} Indikatorfunktion eines Ereignisses
Sei $A$ ein Ereignis. Sei $X=\mathbb{1}_{A}$ eine Indikatorfunktion auf einem Ereignis $A$. Dann gilt
$$
F_{X}(a)= \begin{cases}0 & \text { falls } a<0, \\ 1-\mathbb{P}[A] & \text { falls } 0 \leq a<1 \\ 1 & \text { falls } a \geq 1\end{cases}
$$\\
\yellow{Satz $2.3$ (Einfache Identit{\"a}t):} Seien $a<b$ zwei reelle Zahlen. Dann gilt $\mathbb{P}[a<X \leq b]=F(b)-F(a).$\\
\green{Theorem $2.4$ (Eigenschaften der Verteilungsfunktion): } Sei $X$ eine Z.V. auf einem Wahrscheinlichkeitsraum $(\Omega, \mathcal{F}, \mathbb{P})$. Die Verteilungsfunktion $F=F_{X}: \mathbb{R} \rightarrow[0,1]$ von $X$ erfüllt folgende Eigenschaften:
\begin{enumerate}
    \item $F$ ist monoton wachsend
    \item $F$ ist rechtsstetig ${ }^{a}$
    \item $\lim _{a \rightarrow-\infty} F(a)=0$ und $\lim _{a \rightarrow \infty} F(a)=1$.
\end{enumerate} 
${ }^{a}$ Formal: $F(a)=\lim _{h \downarrow 0} F(a+h)$ für jedes $a \in \mathbb{R}$.
\subsection{Unabhängigkeit von Zufallsvariablen}
\blue{Definition 2.5:} Seien $X_{1}, \ldots, X_{n}$ Zufallsvariablen auf einem $W$-Raum $(\Omega, \mathcal{F}, \mathbb{P})$. Dann heissen $X_{1}, \ldots, X_{n}$ unabhängig falls
$\forall x_{1}, x_{2}, \ldots, x_{n} \in \mathbb{R} \quad \mathbb{P}\left[X_{1} \leq x_{1}, \ldots, X_{n} \leq x_{n}\right]
=\mathbb{P}\left[X_{1} \leq x_{1}\right] \ldots \mathbb{P}\left[X_{n} \leq x_{n}\right]
$\\
\textbf{Bemerkung 2.6:} Man kann zeigen, dass $X_{1}, \ldots, X_{n}$ genau dann unabhängig sind, wenn folgende Bedingung gilt
$
\forall I_{1} \subset \mathbb{R}, \ldots, I_{n} \subset \mathbb{R} \text { Intervalle }\left\{X_{1} \in I_{1}\right\}, \ldots,\left\{X_{n} \in I_{n}\right\} \text { sind unabhängig . }
$\\
\subsection{Gruppierung von Zufallsvariablen}
\yellow{Satz 2.7 (Gruppieren von Zufallsvariablen):} Seien $X_{1}, \ldots, X_{n} n$ unabhängige Zufallsvariablen. Seien $1 \leq i_{1}<i_{2}<\cdots<i_{k} \leq n$ Indexes und $\phi_{1}, \ldots, \phi_{k}$ Abbildungen. Dann sind
$
Y_{1}=\phi_{1}\left(X_{1}, \ldots, X_{i_{1}}\right), Y_{2}=\phi_{2}\left(X_{i_{1}+1}, \ldots, X_{i_{2}}\right) \ldots, Y_{k}=\phi_{k}\left(X_{i_{k-1}+1}, \ldots, X_{i_{k}}\right)
$
unabhängig.
\subsection{Folgen von u.i.v. Zufallsvariablen}
\blue{Definition 2.8:} Eine Folge von Zufallsvariablen $X_{1}, X_{2}, \ldots$ heißt
\begin{enumerate}
    \item unabhängig falls $X_{1}, \ldots, X_{n}$ unabhängig sind, für alle $n \in \mathbb{N}$.
    \item unabhängig und identisch verteilt (uiv) falls sie unabhängig ist und die Zufallsvariablen dieselbe Verteilungsfunktion haben d.h.
    $\forall i, j \quad F_{X_{i}}=F_{X_{j}}.$
\end{enumerate}
\subsection{Transformation von Zufallsvariablen}
Falls $X$ eine Zufallsvariable ist, und $\phi: \mathbb{R} \rightarrow \mathbb{R}$, so schreiben wir
$\phi(X):=\phi \circ X .$
Somit ist $\phi(X)$ eine neue Abbildung von $\Omega \rightarrow \mathbb{R}$, welche in dem nachfolgenden Diagram dargestellt ist:
$\begin{aligned}
    &\Omega \stackrel{X}{\longrightarrow} \mathbb{R} \stackrel{\phi}{\longrightarrow} \quad \mathbb{R}\\
    &\omega \longmapsto X(\omega) \longmapsto \phi(X(\omega)) \text {. }
\end{aligned}$
\subsection{Konstruktion von Zufallsvariablen}
\blue{Definition 2.9:} Sei $p \in[0,1]$. Eine Zufallsvariable $X$ heißt Bernoulli Zufallsvariable mit Parameter $p$ falls
$$
\mathbb{P}[X=0]=1-p \quad \text { und } \quad \mathbb{P}[X=1]=p .
$$
Dabei schreiben wir stets $X \sim \operatorname{Ber}(p)$.\\
\green{Theorem $2.10$ (Existenzsatz von Kolmogorov).} Es existiert ein $W$-Raum $(\Omega, \mathcal{F}, \mathbb{P})$ und eine nicht endliche u.i.v. Folge von Bernoulli 
Zufallsvariablen $X_{1}, X_{2}, \ldots$ auf $(\Omega, \mathcal{F}, \mathbb{P})$ mit Parameter $\frac{1}{2}$.\\
\blue{Definition 2.11:} Eine Zufallsvariable $U$ heißt gleichverteilt auf $[0,1]$ falls ihre Verteilungsfunktion gegeben ist durch
$F_{U}(x)= \begin{cases}0 & x<0 \\ x & 0 \leq x \leq 1 \\ 1 & x>1\end{cases}$\\
Wir schreiben gerade $U \sim \mathcal{U}([0,1])$.\\
\yellow{Satz 2.12} Seien $X_{1}, X_{2}, \ldots$ eine Folge von unabhängigen Bernoulli-Zufallsvariablen mit Parameter $1 / 2$. Für jedes festes $\omega$ haben wir $X_{1}(\omega), X_{2}(\omega) \cdots \in\{0,1\}$. Daraus folgt, dass die unendliche Reihe
$$
Y(\omega)=\sum_{n=1}^{\infty} 2^{-n} X_{n}(\omega)
$$
absolut konvergiert, wobei $Y(\omega) \in[0,1]$ ist. Die Abbildung $Y: \Omega \rightarrow[0,1]$ ist eine gleichverteilte Zufallsvariable auf $[0,1]$.\\
\blue{Definition $2.13$ (Pseudoinverse):} Die Pseudoinverse von $F$ ist eine Abbildung $F^{-1}$ : $(0,1) \rightarrow \mathbb{R}$ definiert durch
$$
\forall \alpha \in(0,1) \quad F^{-1}(\alpha)=\inf \{x \in \mathbb{R}: F(x) \geq \alpha\} .
$$\\
\green{Theorem $2.14$ (Inversionsmethode):} Sei $F: \mathbb{R} \rightarrow[0,1]$ eine Abbildung, welche Eigenschaften (i)-(iii) erfüllt. Sei $U$ eine Gleichverteilte Zufallsvariable. Dann besitzt die Zufallsvariable
$$
X=F^{-1}(U)
$$
gerade die Verteilungsfunktion $F_{X}=F$. \\
\textbf{Bemerkung 2.15:} Wir wollen nochmals kurz erläutern, warum die Definition von $X$ nach 2.14 wohldefiniert ist. Sei $U: \Omega \rightarrow[0,1]$ und $F^{-1}:(0,1) \rightarrow \mathbb{R}$ analog zum obigen Theorem definiert. Dann gilt stets $P[U \in(0,1)=1]$. Strenggenommen ist $X$ bis jetzt nur auf einer Menge mit Wahrscheinlichkeit 1 aber nicht auf ganz $\Omega$ definiert. Wir beheben das Problem mittels folgender Definition
$$
X(\omega)= \begin{cases}F^{-1}(U(\omega)) & \text { falls } U(\omega) \in(0,1) \\ 0 & \text { sonst. }\end{cases}
$$\\
\green{Theorem 2.16:} Seien $F_{1}, F_{2} \ldots$ eine Folge von Funktionen $\mathbb{R}$ auf $[0,1]$, die die Eigenschaften $(i)-($ iii $)$ am Anfang des Abschnitts erfüllen. 
Dann existiert ein Wahrscheinlichkeitsraum $(\Omega, \mathcal{F}, \mathbb{P})$ und eine Folge von unabhängigen Zufallsvariablen $X_{1}, X_{2}, \ldots$ auf diesem Wahrscheinlichkeitsraum, sodass
\begin{enumerate}
    \item für jedes $i$ gilt: $X_{i}$ hat Verteilungsfunktion $F_{i}$ (d.h. $\forall x \mathbb{P}\left[X_{i} \leq x\right]=F_{i}(x)$ ), und
    \item $X_{1}, X_{2}, \ldots$ sind unabhängig.
\end{enumerate}
\section{Diskrete und stetige Zufallsvariablen}
\subsection{Unstetigkeit/Stetigkeit der Verteilungsfunktion $F$}
\yellow{Satz 3.1 (Wahrscheinlichkeit eines Punktes):} Sei $X: \Omega \rightarrow \mathbb{R}$ eine Zufallsvariable mit Verteilungsfunktion $F$. Für jedes a in $\mathbb{R}$ gilt
$\mathbb{P}[X=a]=F(a)-F(a-)$. Sei $a \in \mathbb{R}$ fixiert.
\begin{enumerate}
    \item Wenn $F$ in einem Punkt $a \in \mathbb{R}$ nicht stetig ist, dann ist die ``Sprunghöhe'' $F(a)-F(a-)$ gleich der Wahrscheinlichkeit, dass $X=a$.
    \item Falls $F$ stetig in einem Punkt $a \in \mathbb{R}$ ist, dann gilt $\mathbb{P}[X=a]=0 .$
\end{enumerate}
\subsection{Fast sichere Ereignisse}
\blue{Definition 3.2:} Sei $A \in \mathcal{F}$ ein Ereignis. Wir sagen $A$ tritt fast sicher (f.s.) ein, falls
$\mathbb{P}[A]=1.$\\
\textbf{Bemerkung 3.3:} Wir erweitern gerade diese Notation auf allgemeinere Mengen $A \subset \Omega$ (nicht zwangsweise ein Ereignis): 
Wir sagen dann, dass A fast sicher eintritt, falls ein Ereignis $A^{\prime} \in \mathcal{F}$ existiert, sodass $A^{\prime} \subset A$ 
und $\mathbb{P}\left[A^{\prime}\right]=1$.
\subsection{Diskrete Zufallsvariablen}
\blue{Definition $3.4$ (Diskrete Zufallsvariable):} Eine Zufallsvariable $X: \Omega \rightarrow \mathbb{R}$ heisst diskret falls eine endliche oder abzählbare Menge $W \subset \mathbb{R}$ existiert, sodass
$\mathbb{P}[X \in W]=1.$ ``Die Werte von $X$ liegen in $W$ fast sicher.'' \\
\textbf{Bemerkung 3.5:} Wenn der Grundraum $\Omega$ endlich oder abzählbar ist, dann ist jede $Z u$ fallsvariable $X: \Omega \rightarrow \mathbb{R}$ diskret. 
In der Tat ist das Bild $X(\Omega)=\{x \in \mathbb{R}: \exists \omega \in \Omega X(\omega)=x\}$ endlich oder abzählbar und wir haben $\mathbb{P}[X \in W]=1$, mit $W=X(\Omega)$. \\
\blue{Definition 3.6:} Sei $X$ eine diskrete Zufallsvariable mit Werten in einer endlichen oder abzählbaren Menge $W \subset \mathbb{R}$. Die Zahlenfolge $(p(x))_{x \in W}$ definiert durch
$$
\forall x \in W \quad p(x):=\mathbb{P}[X=x]
$$
heisst Verteilung von $X$. \\
\yellow{Satz 3.7:} Die Verteilung $(p(x))_{x \in W}$ einer diskreten Zufallsvariablen erfüllt
$\sum_{x \in W} p(x)=1 .$\\
\textbf{Bemerkung 3.8:} Umgekehrt, wenn wir eine Folge von Zahlen $(p(x))_{x \in W}$ mit Werten in $[0,1]$ gegeben haben, sodass
$\sum_{x \in W} p(x)=1,$
dann gibt es einen Wahrscheinlichkeitsraum $(\Omega, \mathcal{F}, \mathbb{P})$ und eine Zufallsvariable $X$ mit zugehöriger Verteilung $(p(x))_{x \in W}$. Dies gilt nach dem Existenzsatz 2.16 in Kapitel 2. Diese Beobachtung ist in der Praxis wichtig, denn sie erlaubt uns zu schreiben:
``Sei $X$ eine diskrete Zufallsvariable mit Verteilung $(p(x))_{x \in W}$.''
\subsection{Verteilung $p$ vs. Verteilungsfunktion $F_X$}
\yellow{Satz 3.9:} Sei $X$ eine diskrete Zufallsvariable, dessen Werte in einer endlichen oder abzählbaren Menge $W$ liegen, und deren Verteilung $p$ ist. Dann ist die Verteilungsfunktion von $X$ gegeben durch
$$
\forall x \in \mathbb{R} \quad F_{X}(x)=\sum_{\substack{y \leq x \\ y \in W}} p(y)
$$\\
\subsection{Beispiele diskreter Zufallsvariablen}
\subsubsection{Bernoulli Verteilung}
\blue{Definition $3.10$ (Bernoulli Verteilung):} Es sei $0 \leq p \leq 1$. Eine Zufallsvariable $X$ heisst Bernoulli Zufallsvariable mit Parameter $p$, wenn sie Werte in $W=\{0,1\}$ annimmt und folgendes gilt
$$
\mathbb{P}[X=0]=1-p \quad \text { und } \quad \mathbb{P}[X=1]=p .
$$
In diesem Fall schreiben wir $X \sim \operatorname{Ber}(p)$. \\
\subsubsection{Binomialverteilung}
\blue{Definition $3.11$ (Binomialverteilung):} Sei $0 \leq p \leq 1$, sei $n \in \mathbb{N}$. Eine Zufallsvariable $X$ heisst binomiale Zufallsvariable mit Parametern $n$ und p, wenn sie Werte in $W=\{0, \ldots, n\}$ annimmt und folgendes gilt
$$
\forall k \in\{0, \ldots, n\} \quad \mathbb{P}[X=k]=\left(\begin{array}{l}
n \\
k
\end{array}\right) p^{k}(1-p)^{n-k} .
$$
Wir schreiben dann $X \sim \operatorname{Bin}(n, p)$. \\
\textbf{Bemerkung 3.12:} Wenn wir $p(k)=\left(\begin{array}{l}n \\ k\end{array}\right) p^{k}(1-p)^{n-k}$ definieren, haben wir
$$
\sum_{k=0}^{n} p(k)=\sum_{k=0}^{n}\left(\begin{array}{l}
n \\
k
\end{array}\right) p^{k}(1-p)^{n-k}=(p+1-p)^{n}=1
$$\\
\textbf{Binomialkoeffizient:} $\binom{n}{k} = \frac{n !}{(n-k) ! \cdot k !}$\\
\textbf{Symmetrie der Binomialkoeffizienten:} $\left(\begin{array}{l}n \\ k\end{array}\right)=\left(\begin{array}{c}n \\ n-k\end{array}\right)$ \\
\yellow{Satz $3.13$ (Summe von unabh{\"a}ngigen Bernoulli und Binomial Z.V.):} Sei $0 \leq p \leq 1$, sei $n \in \mathbb{N}$. Seien $X_{1}, \ldots, X_{n}$ unabhängige Bernoulli $Z$.V. mit Parameter $p$. Dann ist
$$
S_{n}:=X_{1}+\cdots+X_{n}
$$
eine binomialverteilte Z.V. mit Parametern $n$ und $p$. \\
\textbf{Bemerkung 3.14:} Insbesondere ist die Verteilung $\operatorname{Bin}(1, p)$ gerade $\operatorname{Ber}(p)$ verteilt. Es sei noch folgendes anzumerken: Falls $X \sim \operatorname{Bin}(m, p), Y \sim \operatorname{Bin}(n, p)$ und $X, Y$ unabhängig sind, dann ist $X+Y \sim \operatorname{Bin}(m+n, p)$ verteilt. \\
\subsubsection{Geometrische Verteilung}
\blue{Definition $3.15$ (Geometrische Verteilung):} Es sei $0<p \leq 1$. Eine Zufallsvariable $X$ heisst geometrische Zufallsvariable mit Parameter $p$, falls sie Werte in $W=$ $\mathbb{N} \backslash\{0\}$ annimmt und folgendes gilt
$$
\forall k \in \mathbb{N} \backslash\{0\} \quad \mathbb{P}[X=k]=(1-p)^{k-1} \cdot p \text {. }
$$
Wir schreiben dann $X \sim \operatorname{Geom}(p)$.\\
\textbf{Bemerkung 3.16:} Für $p=1$ und $k=1$ erscheint in der obigen Gleichung ein Term $0^{0}$, wir verwenden die Konvention $0^{0}=1$ und damit gilt $\mathbb{P}[X=1]=p$. \\
\textbf{Bemerkung 3.17:} Falls wir $p(k)=(1-p)^{k-1} p$ definieren, haben wir
$\sum_{k=1}^{\infty} p(k)=p \sum_{k=1}^{\infty}(1-p)^{k-1}=p \cdot \frac{1}{p}=1$.\\
\yellow{Satz 3.18:} Sei $X_{1}, X_{2}, \ldots$ eine Folge von unendlich vielen unabhängigen BernoulliZ.V. mit Parameter $p$. Dann ist
$T:=\min \left\{n \geq 1: X_{n}=1\right\}$
eine geometrisch verteilte Zufallsvariable mit Parameter $p$. \\
\textbf{Bemerkung 3.19:} Falls wir sagen, dass $T$ eine geometrische Zufallsvariable ist, müssen wir folgendes präzisieren: Tatsächlich kann die Zufallsvariable $T$ den 
Wert $+\infty$ annehmen, wenn alle Zufallsvariablen $X_{i}$ gleich 0 sind. Dies ist jedoch kein Problem für den Bewei des Satzes. Man kann leicht überprüfen, 
dass $\mathbb{P}[T=\infty]=0$ gilt.\\
\yellow{Satz 3.20 (Ged{\"a}chnislosigkeit der Geometrischen Verteilung):} Sei $T \sim \operatorname{Geom}(p)$ für $0<$ $p<1$. Dann gilt
$\forall n \geq 0 \quad \forall k \geq 1 \quad \mathbb{P}[T \geq n+k \mid T>n]=\mathbb{P}[T \geq k]$.\\
\subsubsection{Poisson Verteilung}
\blue{Definition 3.21:} Sei $\lambda>0$ eine positive reelle Zahl. Eine Zufallsvariable $X$ heisst Poisson-Zufallsvariable mit Parameter $\lambda$, wenn sie Werte in $W=\mathbb{N}$ annimmt und folgendes gilt
$$
\forall k \in \mathbb{N} \quad \mathbb{P}[X=k]=\frac{\lambda^{k}}{k !} e^{-\lambda} \text {. }
$$
Wir schreiben dann $X \sim \operatorname{Poisson}(\lambda)$.\\
\textbf{Bemerkung 3.22:} Alternativ definieren wir $p(k)=\frac{\lambda^{k}}{k !} e^{-\lambda}$, haben wir
$\sum_{k=0}^{\infty} p(k)=e^{-\lambda} \sum_{k=0}^{\infty} \frac{\lambda^{k}}{k !}=e^{-\lambda} \cdot e^{\lambda}=1,$\\
\yellow{Satz $3.23$ (Poisson-Approximation der Binomialverteilung):} Sei $\lambda>0$. Für jedes $n \geq 1$ seien $X_{n} \sim \operatorname{Bin}\left(n, \frac{\lambda}{n}\right)$ Zufallsvariablen. Dann gilt
$$
\forall k \in \mathbb{N} \quad \lim _{n \rightarrow \infty} \mathbb{P}\left[X_{n}=k\right]=\mathbb{P}[N=k],
$$
wobei $N$ eine Poisson Zufallsvariable mit Parameter $\lambda$. \\
\yellow{Reproduktivit{\"a}t:} Die Poisson-Verteilung ist reproduktiv, d. h., die Summe $X_{1}+X_{2}+\cdots+X_{n}$ stochastisch unabhängiger Poisson-verteilter Zufallsvariablen $X_{1}, X_{2}, \ldots, X_{n}$ mit den Parametern $\lambda_{1}, \lambda_{2}, \ldots, \lambda_{n}$ ist wieder Poisson-verteilt mit dem Parameter $\lambda_{1}+\lambda_{2}+\cdots+\lambda_{n}$. 
\subsection{Stetige Verteilungen}
\blue{Definition $3.25$ (Stetig verteilte Zufallsvariablen):} Eine Zufallsvariable $X: \Omega \rightarrow \mathbb{R}$ heisst stetig, wenn ihre Verteilungsfunktion $F_{X}$ wie folgt geschrieben werden kann
$$
F_{X}(a)=\int_{-\infty}^{a} f(x) d x \text { für alle a in } \mathbb{R} .
$$
wobei $f: \mathbb{R} \rightarrow \mathbb{R}_{+}$eine nicht-negative Funktion ist. Wir nennen dann $f$ Dichte von $X$.\\
\textbf{Intuition:} $f(x) d x$ ist die Wahrscheinlichkeit, dass $X$ Werte in $[x, x+d x]$ annimmt.\\
\green{Theorem 3.26:} Sei $X$ eine Zufallsvariable. Die Verteilungsfunktion $F_{X}$ sei stetig und stückweise $\mathcal{C}^{1}$, 
d.h. es gibt $x_{0}=-\infty<x_{1}<\cdots<x_{n-1}<x_{n}=+\infty$, sodass $F_{X}$ auf jedem
Intervall $\left(x_{i}, x_{i+1}\right)$ Element von $\mathcal{C}^{1}$ ist. Dann ist $X$ eine stetige Zufallsvariable und die Dichte $f$ kann konstruiert werden, indem man folgendes festlegt
$\forall x \in\left(x_{i}, x_{i+1}\right) \quad f(x)=F_{X}^{\prime}(x)$
mit beliebigen Werten in $x_{1}, \ldots, x_{n-1}$.\\
\subsection{Beispiele stetiger Zufallsvariablen}
\subsubsection{Gleichverteilung}
\blue{Definition $3.27$ (Gleichverteilung auf $[a, b], a<b$.):} Eine stetige Zufallsvariable $X$ heisst gleichverteilt auf $[a, b]$ falls ihre Dichte gegeben ist durch
$$
f_{a, b}(x)= \begin{cases}\frac{1}{b-a} & x \in[a, b], \\ 0 & x \notin[a, b]\end{cases}
$$
Wir schreiben dann stets $X \sim \mathcal{U}([a, b])$.\\
\textbf{Eigenschaften einer gleichverteilten Zufallsvariable $X$ auf $[a, b]$:}
\begin{enumerate}
    \item Die Wahrscheinlichkeit in ein Intervall $[c, c+\ell] \subset[a, b]$ zu fallen ist lediglich abhängig von dessen Länge $\ell$ :
    $\mathbb{P}[X \in[c, c+\ell]]=\frac{\ell}{b-a} .$
    \item Die Verteilungsfunktion $X$ ist gegeben durch
    $F_{X}(x)= \begin{cases}0 & x<a, \\ \frac{x-a}{b-a} & a \leq x \leq b, \\ 1 & x>b .\end{cases}$
\end{enumerate}
\subsubsection{Exponentialverteilung}
\blue{Definition 3.28 (Exponentialverteilung mit Parameter $\lambda>0$ ):} Eine stetige Zufallsvariable $T$ heisst exponentialverteilt mit Parameter $\lambda>0$ falls ihre Dichte gegeben ist durch
$$
f_{\lambda}(x)= \begin{cases}\lambda e^{-\lambda x} & x \geq 0 \\ 0 & x<0\end{cases}
$$
Wir schreiben dann stets $T \sim \exp (\lambda)$.\\
\textbf{Eigenschaften einer exponentialverteilten Zufallsvariable $T$ mit Parameter $\lambda$:}
\begin{enumerate}
    \item  Die Wahrscheinlichkeit des Wartens ist exponentiell klein:
    $\forall t \geq 0 \quad \mathbb{P}[T>t]=e^{-\lambda t} .$
    \item $T$ besitzt die Eigenschaft der Gedächnislosigkeit
    $\forall t, s \geq 0 \quad \mathbb{P}[T>t+s \mid T>t]=[T>s] .$
\end{enumerate}
Die Verteilungsfunktion sieht folgendermassen aus
$$
F_{\lambda}(x)= \begin{cases}1 - e^{-\lambda x} & x \geq 0 \\ 0 & x<0\end{cases}.
$$
\subsubsection{Normalverteilung}
\blue{Definition 3.29:} Eine stetige Zufallsvariable $X$ heisst normal verteilt mit Parametern $m$ und $\sigma^{2}>0$ falls ihre Dichte gegeben ist durch
$$
f_{m, \sigma}(x)=\frac{1}{\sqrt{2 \pi \sigma^{2}}} e^{-\frac{(x-m)^{2}}{2 \sigma^{2}}}
$$
Wir schreiben dann stets $X \sim \mathcal{N}\left(m, \sigma^{2}\right)$.\\
\textbf{Eigenschaften der Normalverteilung:}
\begin{enumerate}
    \item Seien $X_{1}, \ldots, X_{n}$ unabhängige normalverteilte Zufallsvariablen mit Parametern $\left(m_{1}, \sigma_{1}^{2}\right), \ldots,\left(m_{n}, \sigma_{n}^{2}\right)$, dann ist
    $Z=m_{0}+\lambda_{1} X_{1}+\ldots+\lambda_{n} X_{n}$
    eine normalverteilte Zufallsvariable mit Parametern $m=m_{0}+\lambda_{1} m_{1}+\cdots+\lambda_{n} m_{n}$ und $\sigma^{2}=\lambda_{1}^{2} \sigma_{1}^{2}+\cdots+\lambda_{n}^{2} \sigma_{n}^{2}$
    \item Wir sprechen im Fall von $X \sim \mathcal{N}(0,1)$, gerade von einer standardnormalverteilten Zufallsvariable. Man merke sich dann folgende Beziehung
    $Z=m+\sigma \cdot X$
    wobei $X$ eine normalverteilte Zufallsvariable mit Parametern $m$ und $\sigma^{2}$ ist.
    \item Falls $X$ normalverteilt mit Parametern $m$ und $\sigma^{2}$ ist, dann liegt die ``meiste'' Wahrscheinlichkeitsmasse der Z.V. im Intervall $[m-3 \sigma, m+3 \sigma]$. Präzise gilt gerade
    $\mathbb{P}[|X-m| \geq 3 \sigma] \leq 0.0027$
\end{enumerate}
\section{Der Erwartungswert}
\subsection{Der allgemeine Erwartungswert}
\blue{Definition 4.1:} Sei $X: \Omega \rightarrow \mathbb{R}_{+}$eine Zufallsvariable mit nicht-negativen Werten. Dann heisst
$$
\mathbb{E}[X]=\int_{0}^{\infty}\left(1-F_{X}(x)\right) d x
$$
der Erwartungswert von $X$.\\
\textbf{Bemerkung 4.2:} Der Erwartungswert kann sowohl endliche also auch nicht endliche Werte annehmen.\\
\yellow{Satz 4.3:} Sei $X$ eine nicht-negative Zufallsvariable. Dann gilt
$\mathbb{E}[X] \geq 0 .$
Gleichheit gilt genau dann wenn $X=0$ fast sicher hält.\\
\blue{Definition 4.4:} Sei $X$ eine Zufallsvariable. Falls $\mathbb{E}[|X|]<\infty$, dann heisst\\
$X_{+}(\omega)=\left\{\begin{array}{ll}X(\omega) & \text { falls } X(\omega) \geq 0, \\ 0 & \text { falls } X(\omega)<0,\end{array} \quad\right.$ und 
$\quad X_{-}(\omega)= \begin{cases}-X(\omega) & \text { falls } X(\omega) \leq 0, \\ 0 & \text { falls } X(\omega)>0 .\end{cases}$\\
$
\mathbb{E}[X]=\mathbb{E}\left[X_{+}\right]-\mathbb{E}\left[X_{-}\right] .$
Erwartungswert von $X$.\\
\subsection{Erwartungswert einer diskreten Zufallsvariable}
\yellow{Satz 4.6:} Sei $X: \Omega \rightarrow \mathbb{R}$ eine diskrete Zufallsvariable dessen Werte in $W$ (endlich oder abzählbar) fast sicher liegen. Sei $\phi: \mathbb{R} \rightarrow \mathbb{R}$ eine Abbildung. Dann gilt
$$
\mathbb{E}[\phi(X)]=\sum_{x \in W} \phi(x) \cdot \mathbb{P}[X=x],
$$
solange der Erwartungswert wohldefiniert ist.\\
\subsubsection{Bernoulli Zufallsvariable}
Sei $X$ eine Bernoulli Zufallsvariable mit Parameter $p$. Dann gilt
$\mathbb{E}[X]=p$.
\subsubsection{Binomial Zufallsvariable}
Sei $X \sim \operatorname{Bin}(n, p)$, dann gilt $\mathbb{E}[X] = np$
\subsubsection{Poisson Zufallsvariable}
Sei $X$ Poisson-verteilt mit Parameter $\lambda>0$, dann gilt
$\mathbb{E}[X]=\lambda .$
\subsubsection{Indikator Zufallsvariable}
Sei $A \in \mathcal{F}$ ein Ereignis. Sei $\mathbb{1}_{A}$ die Indikator Funktion auf $A$, dann gilt $\mathbb{E}[\mathbb{1}_{A}]= \mathbb{P}[A] .$
\subsubsection{geometrische Zufallsvariable}
Sei $X \sim \operatorname{Geom}(p)$, dann gilt $\mathbb{E}[X] = \frac{1}{p}$
\subsection{Erwartungswert stetiger Zufallsvariablen}
\yellow{Satz 4.8:} Sei $X$ eine stetige Zufallsvariable mit Dichte $f$. Dann gilt
$$\mathbb{E}[X]=\int_{-\infty}^{\infty} x \cdot f(x) d x,$$
solange das Integral wohldefiniert ist.\\
\green{Theorem 4.9:} Sei $X$ eine stetige Zufallsvariable mit Dichte $f$. Sei $\phi: \mathbb{R} \rightarrow \mathbb{R}$ eine Abbildung, sodass $\phi(X)$ eine Zufallsvariable ist. Dann gilt
$$E[\phi(X)]=\int_{-\infty}^{\infty} \phi(x) f(x) d x$$
solange das Integral wohldefiniert ist.\\
\subsubsection{Exponential Zufallsvariable}
Sei $X \sim \exp (\lambda)$. Dann gilt $\mathbb{E}[X] = \frac{1}{\lambda}$.
\subsubsection{gleichverteilte Zufallsvariable}
Sei $X \sim \mathcal{U}([a, b])$. Dann gilt $\mathbb{E}[X] = \frac{a + b}{2}$.
\subsubsection{Normalverteilung}
Sei $X \sim \mathcal{N}\left(\mu , \sigma^{2}\right)$. Dann gilt $\mathbb{E}[X] = \mu$.
\subsection{Rechnen mit Zufallsvariable}
\green{Theorem $4.10$ (Linearit{\"a}t des Erwartungswert):} Seien $X, Y: \Omega \rightarrow \mathbb{R}$ Zufallsvariablen, sei $\lambda \in \mathbb{R}$. 
Falls die Erwartungswerte wohldefiniert sind gilt
\begin{enumerate}
    \item $\mathbb{E}[\lambda \cdot X]=\lambda \cdot \mathbb{E}[X]$
    \item $\mathbb{E}[X+Y]=\mathbb{E}[X]+\mathbb{E}[Y]$.
\end{enumerate}
\textbf{Bemerkung 4.11:} Die Zufallsvariablen $X$ und $Y$ müssen dabei nicht unabhängig sein. \\
\textbf{Bemerkung 4.12:} Unter Anwendung der Induktion für $n \geq 1$ ergibt sich direkt
$\mathbb{E}\left[\lambda_{1} X_{1}+\lambda_{2} X_{2}+\cdots+\lambda_{n} X_{n}\right]=\lambda_{1} \mathbb{E}\left[X_{1}\right]+\lambda_{2} \mathbb{E}\left[X_{2}\right]+\cdots+\lambda_{n} \mathbb{E}\left[X_{n}\right]$
für jede $Z . V . X_{1}, X_{2}, \ldots, X_{n}: \Omega \rightarrow E$, und für jedes $\lambda_{1}, \lambda_{2}, \cdots, \lambda_{n} \in \mathbb{R}$, unter der Annahme, dass die Erwartungswerte wohldefiniert sind. \\
\green{Theorem 4.13:} Seien $X, Y$ zwei Zufallsvariablen. Falls $X$ und $Y$ unabhängig sind, dann ist
$\mathbb{E}[X Y]=\mathbb{E}[X] \mathbb{E}[Y]$. \\
\subsection{Extremwert Formel}
\yellow{Satz $4.14$ (Tailsum-Formel f{\"u}r nichtnegative Zufallsvariablen):} Sei $X$ eine Zufallsvariable, sodass $X \geq 0$ fast sicher gilt. Dann folgt
$\mathbb{E}[X]=\int_{0}^{\infty} \mathbb{P}[X>x] d x .$\\
\yellow{Satz 4.15 (Extremwert Formel):} Sei $X$ eine diskrete Zufallsvariable mit Werten in $\mathbb{N}=\{0,1,2, \ldots\}$. Dann gilt folgende Identität
$\mathbb{E}[X]=\sum_{n=1}^{\infty} \mathbb{P}[X \geq n]$.\\
\subsection{Charakterisierung der Eigenschaften von Z.V.}
\yellow{Satz 4.16. Sei $X$ eine Zufallsvariable:} Sei $f: \mathbb{R} \rightarrow \mathbb{R}_{+}$eine Abbildung, sodass $\int_{-\infty}^{+\infty} f(x) d x=1$. Dann sind folgende Aussagen äquivalent
\begin{enumerate}
    \item $X$ ist stetig mit Dichte $f$,
    \item Für jede Abbildung stückweise stetige, beschränkte Abbildung $\phi: \mathbb{R} \rightarrow \mathbb{R}$ gilt
    $\mathbb{E}[\phi(X)]=\int_{-\infty}^{\infty} \phi(x) f(x) d x$.
\end{enumerate}
\green{Theorem 4.17:} Seien $X, Y$ zwei diskrete Zufallsvariablen. Die folgenden Aussagen sind äquivalent
\begin{enumerate}
    \item $X, Y$ sind unabhängig,
    \item Für jedes $\phi: \mathbb{R} \rightarrow \mathbb{R}, \psi: \mathbb{R} \rightarrow \mathbb{R}$ (messbar) beschränkt und stückweise stetig gilt
    $\mathbb{E}[\phi(X) \psi(Y)]=\mathbb{E}[\phi(X)] \mathbb{E}[\psi(Y)]$.
\end{enumerate}
\green{Theorem 4.18:} Seien $X_{1}, \ldots, X_{n} n$ Zufallsvariablen. Die folgenden Aussagen sind äquivalent
\begin{enumerate}
    \item $X_{1}, \ldots, X_{n}$ sind unabhängig,
    \item Für jedes $\phi_{1}: \mathbb{R} \rightarrow \mathbb{R}, \ldots, \phi_{n}: \mathbb{R} \rightarrow \mathbb{R}$ (messbar) beschränkt gilt
    $\mathbb{E}\left[\phi_{1}\left(X_{1}\right) \cdots \phi_{n}\left(X_{n}\right)\right]=\mathbb{E}\left[\phi_{1}\left(X_{1}\right)\right] \cdots \mathbb{E}\left[\phi_{n}\left(X_{n}\right)\right]$
\end{enumerate}
\subsection{Ungleichungen}
\yellow{Satz 4.19:} Seien $X, Y$ zwei Zufallsvariablen, sodass
$X \leq Y \text { f.s. }$
gilt. Falls beide Erwartungswerte wohldefiniert sind, folgt dann
$\mathbb{E}[X] \leq \mathbb{E}[Y]$ fast sicher. \\
\subsection{Markow Ungleichung}
\green{Theorem $4.20$ (Markow-Ungleichung):} Sei $X$ eine nicht-negative Zufallsvariable. Für jedes $a>0$ gilt dann
$\mathbb{P}[X \geq a] \leq \frac{\mathbb{E}[X]}{a}$.
\subsection{Jensen Ungleichung}
\green{Theorem $4.21$ (Jensen Ungleichung):} Sei $X$ eine Zufallsvariable. Sei $\phi: \mathbb{R} \rightarrow \mathbb{R}$ eine konvexe Funktion. Falls $\mathbb{E}[\phi(X)]$ und $\mathbb{E}[X]$ wohldefiniert sind, gilt
$\phi(\mathbb{E}[X]) \leq \mathbb{E}[\phi(X)]$.
\subsection{Cauchy-Schwarz Ungleichungen}
\green{Theorem 4.22:} Seien $X,Y$ zwei Zufallsvariablen mit $\mathbb{E}[X^2],\mathbb{E}[Y^2] < \infty$. Dann gilt 
$\mathbb{E}[XY] \leq \sqrt{\mathbb{E}[X^2]} \cdot \sqrt{\mathbb{E}[Y^2]}$.
\subsection{Varianz}
\blue{Definition 4.22:} Sei $X$ eine Zufallsvariable, sodass $\mathbb{E}\left[X^{2}\right]<\infty$. Wir definieren die $V a$ rianz von $X$ durch
$\sigma_{X}^{2}=\mathbb{E}\left[(X-m)^{2}\right], \quad \text { wobei } m=\mathbb{E}[X]$
Die Wurzel aus $\sigma_{X}^{2}$ nennen wir gerade die Standardabweichung von $X$.\\
\textbf{Bemerkung 4.23:} Falls $\mathbb{E}\left[X^{2}\right]<\infty$, dann gilt gerade $\mathbb{E}[|X|]<\infty$ durch Gleichung. (4.7) und somit ist $m=\mathbb{E}[X]$ wohldefiniert.\\
\yellow{Satz $4.24$ (Grundlegende Eigenschaften der Varianz):}
\begin{enumerate}
    \item  Sei $X$ eine Zufallsvariable mit $\mathbb{E}\left[X^{2}\right]<\infty$. Dann gilt
    $\sigma_{X}^{2}=\mathbb{E}\left[X^{2}\right]-\mathbb{E}[X]^{2}$
    \item Sei $X$ eine Zufallsvariable mit $\mathbb{E}\left[X^{2}\right]<\infty$ und sei $\lambda \in \mathbb{R}$. Dann gilt
    $\sigma_{\lambda X}^{2}=\lambda^{2} \cdot \sigma_{X}^{2}.$
    \item Seien $X_{1}, \ldots, X_{n} n$-viele paarweise unabhängigen $Z$ ufallsvariablen und $S=X_{1}+\cdots+$ $X_{n}$. Dann gilt
    $\sigma_{S}^{2}=\sigma_{X_{1}}^{2}+\cdots+\sigma_{X_{n}}^{2}.$
\end{enumerate}
\green{Theorem 4.24:} Sei $X$ eine Zufallsvariable mit $\mathbb{E}\left[X^{2}\right]<\infty$. Dann gilt für alle $a \geq 0$
$\mathbb{P}[|X-m| \geq a] \leq \frac{\sigma_{X}^{2}}{a^{2}}, \quad \text { where } m=\mathbb{E}[X]$.
\subsection{Beispiele Varianz von Zufallsvariablen}
\subsubsection{Bernoulli Zufallsvariable}
Sei $X$ eine Bernoulli Zufallsvariable mit Parameter $p$. Dann gilt
$\text{Var}[X] = p \cdot (1 - p)$.
\subsubsection{Binomial Zufallsvariable}
Sei $X \sim \operatorname{Bin}(n, p)$, dann gilt $\text{Var}[X] = n\cdot p \cdot (1 - p)$.
\subsubsection{Poisson Zufallsvariable}
Sei $X$ Poisson-verteilt mit Parameter $\lambda>0$, dann gilt
$\text{Var}[X] = \lambda .$
\subsubsection{Indikator Zufallsvariable}
Sei $A \in \mathcal{F}$ ein Ereignis. Sei $\mathbb{1}_{A}$ die Indikator Funktion auf $A$, dann gilt $\text{Var}[\mathbb{1}_{A}]= \mathbb{P}[A] - (\mathbb{P}[A])^2.$
\subsubsection{geometrische Zufallsvariable}
Sei $X \sim \operatorname{Geom}(p)$, dann gilt $\text{Var}[X] = \frac{1}{p^2} - \frac{1}{p}$
\subsubsection{Exponential Zufallsvariable}
Sei $X \sim \exp (\lambda)$. Dann gilt $\text{Var}[X] = \frac{1}{\lambda^2}$.
\subsubsection{gleichverteilte Zufallsvariable}
Sei $X \sim \mathcal{U}([a, b])$. Dann gilt $\text{Var}[X] = \frac{1}{12} \cdot (b - a)^2$.
\subsubsection{Normalverteilung}
Sei $X \sim \mathcal{N}\left(\mu , \sigma^{2}\right)$. Dann gilt $\text{Var}[X] = \sigma^{2}$.
\subsection{Kovarianz}
\blue{Definition 4.25:} Seien $X, Y$ zwei Zufallsvariablen mit endlichen zweiten Momenten $\mathbb{E}\left[X^{2}\right]<\infty$ und $\mathbb{E}\left[Y^{2}\right]<\infty$. Wir definieren die Kovarianz zwischen $X$ und $Y$ durch
$\operatorname{Cov}(X, Y)=\mathbb{E}[X Y]-\mathbb{E}[X] \mathbb{E}[Y]$. \\
\textbf{Bemerkung:} Die endlichen zweiten Momente von $X$ und $Y$ ermöglichen die Wohldefiniertheit der Kovarianz von $X$ und $Y$. Hierfür wende man die elementare Ungleichung $|X Y| \leq \frac{1}{2} X^{2}+\frac{1}{2} Y^{2}$ in Kombination mit Monotonie und Linearität des Erwartungswerts an, um folgende Ungleichung zu erhalten
$$
\mathbb{E}[|X Y|] \leq \frac{1}{2} \mathbb{E}\left[X^{2}\right]+\frac{1}{2} \mathbb{E}\left[Y^{2}\right]<\infty .
$$
Analog zum Abschnitt 4, verschwindet die Kovarianz von unabhängigen Zufallsvariablen $X$ und $Y$, somit gilt
$$
X, Y \text { unabhängig } \Longrightarrow \operatorname{Cov}(X, Y)=0 \text {. }
$$
Die Umgekehrte Implikation ist falsch (Siehe Serie 6.6). Nichtsdestotrotz sehen wir in Abschnitt 6, dass wir eine Charakterisierung mittels beschränkten und stetigen Testfunktionen erhalten. Mittels Theorem 4.17, erhalten wir folgende Charakterisierung
$X, Y$ Unabhängig $\Longleftrightarrow \forall \phi, \psi$ stückweise stetig, beschränkt $\operatorname{Cov}(\phi(X), \psi(Y))=0$.
\section{Gemeinsame Verteilung}
\subsection{Gemeinsame diskrete Verteilung}
\blue{Definition 5.1:} Seien $X_{1}, \ldots, X_{n} n$ diskrete Zufallsvariablen, sei $W_{i} \subset \mathbb{R}$ endlich oder abzählbar, wobei $X_{i} \in W_{i}$ fast sicher gilt. Die gemeinsame Verteilung von $\left(X_{1}, \ldots, X_{n}\right)$ ist eine Familie $p=\left(p\left(x_{1}, \ldots, x_{n}\right)\right)_{x_{1} \in W_{1}, \ldots, x_{n} \in W_{n}}$, wobei jedes Mitglied definiert ist durch
$p\left(x_{1}, \ldots, x_{n}\right)=\mathbb{P}\left[X_{1}=x_{1}, \ldots, X_{n}=x_{n}\right] .$\\
\yellow{Satz 5.2:} Eine gemeinsame Verteilung von Zufallsvariablen $X_{1}, \ldots, X_{n}$ erfüllt
$\sum_{x_{1} \in W_{1}, \ldots, x_{n} \in W_{n}} p\left(x_{1}, \ldots, x_{n}\right)=1 .$\\
\yellow{Satz 5.3:} Sei $n \geq 1$ und seien $\phi: \mathbb{R}^{n} \rightarrow \mathbb{R}$ Abbildungen. Seien $X_{1}, \ldots, X_{n} n$ diskrete Zufallsvariablen in $(\Omega, \mathcal{F}, \mathbb{P})$, welche fast sicher Werten in endlichen oder abzählbaren Mengen $W_{1}, \ldots, W_{n}$ annehmen. Dann ist $Z=\phi\left(X_{1}, \ldots, X_{n}\right)$ eine diskrete Zufallsvariable, welche fast sicher Werte in $W=\phi\left(W_{1} \times \cdots \times W_{n}\right)$ annimmt. Zudem ist die Verteilung von $Z$ gegeben durch
$$
\forall z \in W \quad \mathbb{P}[Z=z]=\sum_{\substack{x_{1} \in W_{1}, \ldots, x_{n} \in W_{n} \\ \phi\left(x_{1}, \ldots, x_{n}\right)=z}} \mathbb{P}\left[X_{1}=x_{1}, \ldots X_{n}=x_{n}\right]
$$\\
\yellow{Satz 5.4 (Randverteilung):} Seien $X_{1}, \ldots, X_{n} n$ diskrete Zufallsvariablen mit gemeinsamer Verteilung $p=\left(p\left(x_{1}, \ldots, x_{n}\right)\right)_{x_{1} \in W_{1}, \ldots, x_{n} \in W_{n}}$. Für jedes $i$ gilt
$
\forall z \in W_{i} \quad \mathbb{P}\left[X_{i}=z\right]=\sum_{x_{1}, \ldots, x_{i-1}, x_{i+1}, \ldots, x_{n}} p\left(x_{1}, \ldots, x_{i-1}, z, x_{i+1}, \ldots, x_{n}\right) \text {. }
$\\
\yellow{Satz 5.5 (Erwartungswert des Bildes):} Seien $X_{1}, \ldots, X_{n} n$ diskrete Zufallsvariablen mit gemeinsamer Verteilung $p=\left(p\left(x_{1}, \ldots, x_{n}\right)\right)_{x_{1} \in W_{1}, \ldots, x_{n} \in W_{n}}$. Sei $\phi: \mathbb{R}^{n} \rightarrow \mathbb{R}$, dann gilt
$$
\mathbb{E}\left[\phi\left(X_{1}, \ldots, X_{n}\right)\right]=\sum_{x_{1}, \ldots, x_{n}} \phi\left(x_{1}, \ldots, x_{n}\right) p\left(x_{1}, \ldots, x_{n}\right),
$$
solange die Summe wohldefiniert ist.\\
\yellow{Satz 5.6:} Seien $X_{1}, \ldots, X_{n}$ diskrete Zufallsvariablen mit gemeinsamer Verteilung $p=$ $\left(p\left(x_{1}, \ldots, x_{n}\right)\right)_{x_{1} \in W_{1}, \ldots, x_{n} \in W_{n}}$. Die folgenden Aussagen sind äquivalent
\begin{enumerate}
    \item $X_{1}, \ldots, X_{n}$ sind unabhängig,
    \item $p\left(x_{1}, \ldots, x_{n}\right)=\mathbb{P}\left[X_{1}=x_{1}\right] \cdots \mathbb{P}\left[X_{n}=x_{n}\right]$ für jedes $x_{1} \in W_{1}, \ldots, x_{n} \in W_{n}$.
\end{enumerate}
\subsection{Stetige Gemeinsame Verteilung}
\blue{Definition 5.7:} Sei $n \geq 1$. Wir sagen, dass die Zufallsvariablen $X_{1}, \ldots, X_{n}: \Omega \rightarrow \mathbb{R}$ eine stetige gemeinsame Verteilung besitzen, falls eine Abbildung $f: \mathbb{R}^{n} \rightarrow \mathbb{R}_{+}$ existiert, sodass
$$
\mathbb{P}\left[X_{1} \leq a_{1}, \ldots, X_{n} \leq b\right]=\int_{-\infty}^{a_{1}} \cdots \int_{-\infty}^{a_{n}} f\left(x_{1}, \ldots, x_{n}\right) d x_{n} \ldots d x_{1}
$$
für jedes $a_{1}, \ldots, a_{n} \in \mathbb{R}$ gilt. Obige Abbildung $f$ nennen wir gerade gemeinsame Dichte von $\left(X_{1}, \ldots, X_{n}\right)$.\\
\yellow{Satz 5.9:} Sei $f$ die gemeinsame Dichte der Zufallsvariablen $\left(X_{1}, \ldots, X_{n}\right)$. Dann gilt
$\int_{-\infty}^{\infty} \cdots \int_{-\infty}^{\infty} f\left(x_{1}, \ldots, x_{n}\right) d x_{n} \ldots d x_{1}=1$.\\
\yellow{Satz 5.10 (Erwartungswert):} Sei $\phi: \mathbb{R}^{n} \rightarrow \mathbb{R}$ eine Abbildung. Falls $X_{1}, \ldots, X_{n}$ eine gemeinsame Dichte $f$ besitzen, dann lässt sich der Erwartungswert der $Z$ ufallsvariablen $Z=\phi\left(X_{1}, \ldots, X_{n}\right)$ mittels
$\mathbb{E}[\phi(X, Y)]=\int_{-\infty}^{\infty} \cdots \int_{-\infty}^{\infty} \phi\left(x_{1}, \ldots, x_{n}\right) \cdot f\left(x_{1}, \ldots, x_{n}\right) d x_{1} \ldots d x_{n},$
berechnen (solange das Integral wohldefiniert ist). \\
\blue{Randverteilung:}
Falls $X, Y$ eine gemeinsame Dichte $f_{X, Y}$ besitzt, dann gilt
$$
\begin{aligned}
\mathbb{P}[X \leq a] &=\mathbb{P}[X \in[-\infty, a], Y \in[-\infty, \infty]] \\
&=\int_{-\infty}^{a}\left(\int_{-\infty}^{\infty} f(x, y) d y\right) d x .
\end{aligned}
$$
Somit ist $X$ stetig mit folgender Dichte
$$
f_{X}(x)=\int_{-\infty}^{\infty} f(x, y) d y .
$$
Analog ist $Y$ stetig mit folgender Dichte
$$
f_{Y}(y)=\int_{-\infty}^{\infty} f(x, y) d x
$$\\
\green{Theorem 5.11:} Seien $X_{1}, \ldots, X_{n}$ Zufallsvariablen mit Dichten $f_{1}, \ldots f_{n}$. Dann ist folgende Aussagen äquivalent
\begin{enumerate}
    \item $X_{1}, \ldots, X_{n}$ sind unabhängig,
    \item  $X_{1}, \ldots, X_{n}$ sind insgesamt stetig mit gemeinsamer Dichte
    $f\left(x_{1}, \ldots, x_{n}\right)=f_{1}\left(x_{1}\right) \ldots f_{n}\left(x_{n}\right).$
\end{enumerate}
\section{Grenzwertsätze}
\textbf{Vorbemerkung:} In diesem Kapitel fixieren wir einen Wahrscheinlichkeitsraum $(\Omega, \mathcal{F}, \mathbb{P})$ und eine Folge von u.i.v.-Zufallsvariablen $X_{1}, X_{2}, \ldots$. Mit anderen Worten, wir erhalten Zufallsvariablen $X_{i}: \Omega \rightarrow \mathbb{R}$, so dass
$
\forall i_{1}<\cdots<i_{k} \forall x_{1}, \ldots x_{k} \in \mathbb{R} \quad \mathbb{P}\left[X_{i_{1}} \leq x_{1}, \ldots, X_{i_{k}} \leq x_{k}\right]=F\left(x_{1}\right) \cdots F\left(x_{k}\right)
$. Zudem ist $S_n = X_1 + X_2 + \dots + X_n$.
\subsection{Gesetz der grossen Zahlen (GGZ)}
\green{Theorem 6.1:} Sei $\mathbb{E}\left[\left|X_{1}\right|\right]<\infty$. Setzte $m=\mathbb{E}\left[X_{1}\right]$ dann gilt
$$
\lim _{n \rightarrow \infty} \frac{X_{1}+\cdots+X_{n}}{n}=m \text { fast sicher. }
$$\\
\subsection{Konvergenz in Verteilung}
\blue{Definition 6.3:} Seien $\left(X_{n}\right)_{n \in \mathbb{N}}$ und $X$ Zufallsvariablen. Wir schreiben
$X_{n} \underset{\approx}{\text { Approx }} X \text { as } n \rightarrow \infty$
falls für jedes $x \in \mathbb{R}$
$\lim _{n \rightarrow \infty} \mathbb{P}\left[X_{n} \leq x\right]=\mathbb{P}[X \leq x]$\\
\subsection{Zentraler Grenzwertsatz}
\green{Theorem $6.4$ (Zentraler Grenzwertsatz (ZGWS)):} Nehme an, dass der Erwartungswert $\mathbb{E}\left[X_{1}^{2}\right]$ wohldefiniert und endlich ist. Setzte $m=\mathbb{E}\left[X_{1}\right]$ und $\sigma^{2}=\operatorname{Var}\left(X_{1}\right)$, dann gilt folgender Grenzwert
$$\mathbb{P}\left[\frac{S_{n}-n \cdot m}{\sqrt{\sigma^{2} n}} \leq a\right] \underset{n \rightarrow \infty}{\longrightarrow} \Phi(a)=\frac{1}{\sqrt{2 \pi}} \int_{-\infty}^{a} e^{-x^{2} / 2} d x$$
für jedes $a \in \mathbb{R}$. \\
\textbf{Bemerkung:} Beachte gerade, dass $\Phi$ gerade die Verteilungsfunktion einer Zufallsvariable $Z \sim$ $\mathcal{N}(0,1)$ ist. Der Satz besagt somit, dass für grosse $n \in \mathbb{N}$ die Zufallsvariable
$$
Z_{n}=\frac{S_{n}-n \cdot m}{\sqrt{\sigma^{2} n}}
$$
in Verteilung $Z \sim \mathcal{N}(0,1)$ ähnelt.
\section{Schätzer}
\subsection{Grundbegriffe}
\blue{Definition 1.1:} Ein Schätzer ist eine Zufallsvariable $T: \Omega \rightarrow \mathbb{R}$ der Form
$$
T=t\left(X_{1}, \ldots, X_{n}\right),
$$
wobei $t: \mathbb{R}^{n} \rightarrow \mathbb{R}$.
\subsection{Bias}
\blue{Definition 1.2:} Ein Schätzer $T$ heisst erwartungstreu für $\theta$, falls für alle $\theta \in \Theta$ gilt
$\mathbb{E}_{\theta}[T]=\theta$.\\
\blue{Definition 1.3:} Sei $\theta \in \Theta$, und $T$ ein Schätzer. Der Bias (oder erwartete Schätzfehler) von $T$ im Modell $\mathbb{P}_{\theta}$ ist definiert als
$$
\mathbb{E}_{\theta}[T]-\theta
$$
Der mittlere quadratische Schätzfehler (``mean squared error'', MSE) von $T$ im Modell $\mathbb{P}_{\theta}$ ist definiert als
$$
\operatorname{MSE}_{\theta}[T]:=\mathbb{E}_{\theta}\left[(T-\theta)^{2}\right]
$$
\textbf{Bemerkung:} Man kann den MSE zerlegen als
$$
\operatorname{MSE}_{\theta}[T]=\mathbb{E}_{\theta}\left[(T-\theta)^{2}\right]=\operatorname{Var}_{\theta}[T]+\left(\mathbb{E}_{\theta}[T]-\theta\right)^{2},
$$
also in die Summe aus der Varianz des Schätzers $T$ und dem Quadrat des Bias. Für erwartungstreue Schätzer sind Varianz und MSE dasselbe. \\
\subsection{Die Maximum-Likelihood-Methode (ML-Methode)}
\blue{Definition 1.4:} Die Likelihood-Funktion ist
$$
L\left(x_{1}, \ldots, x_{n} ; \theta\right):= \begin{cases}p_{\vec{X}}\left(x_{1}, \ldots, x_{n} ; \theta\right) & \text { im diskreten Fall, } \\ f_{\vec{X}}\left(x_{1}, \ldots, x_{n} ; \theta\right) & \text { im stetigen Fall. }\end{cases}
$$
mit $p_{\vec{X}}\left(x_{1}, \ldots, x_{n} ; \theta\right)=\prod_{i=1}^{n} p_{X}\left(x_{i} ; \theta\right)$ und $f_{\vec{X}}\left(x_{1}, \ldots, x_{n} ; \theta\right)=\prod_{i=1}^{n} f_{X}\left(x_{i} ; \theta\right)$.
Die Funktion $\log L\left(x_{1}, \ldots, x_{n} ; \theta\right)$ heisst \textbf{log-Likelihood-Funktion}. \\
\blue{Definition 1.5:} Für jedes $x_{1}, \ldots, x_{n}$, sei $t_{M L}\left(x_{1}, \ldots, x_{n}\right) \in \mathbb{R}$ der Wert, der $\theta \mapsto$ $L\left(x_{1}, \ldots, x_{n} ; \theta\right)$ als Funktion von $\theta$ maximiert. D.h.,
$$
L\left(x_{1}, \ldots, x_{n} ; t_{M L}\left(x_{1}, \ldots, x_{n}\right)\right)=\max _{\theta \in \Theta} L\left(x_{1}, \ldots, x_{n} ; \theta\right)
$$
Ein Maximum-Likelihood-Schätzer (ML-Schätzer) $T_{\mathrm{ML}}$ für $\theta$ wird definiert durch $T_{\mathrm{ML}}=t_{\mathrm{ML}}\left(X_{1}, \ldots, X_{n}\right)$.\\
\textbf{Bemerkung:}
In den Rechnungen arbeitet man oft mit $L\left(x_{1}, \ldots, x_{n} ; \theta\right)$, insbesondere beim Maximieren über 
$\theta$. Das optimale $\theta^{*}$ ist dann eine Funktion $t_{\mathrm{ML}}\left(x_{1}, \ldots, x_{n}\right)$ von 
$x_{1}, \ldots, x_{n}$. Damit der resultierende Schätzer $T_{\mathrm{ML}}$ von der Stichprobe $X_{1}, \ldots, X_{n}$ abhängt, 
muss dann aber $x_{1}, \ldots, x_{n}$ durch $X_{1}, \ldots, X_{n}$ ersetzt werden, d.h. der Maximum-Likelihood-Schätzer 
ist $T_{\mathrm{ML}}=t_{\mathrm{ML}}\left(X_{1}, \ldots, X_{n}\right)$. \\
\section{Konfidenzintervalle}
\subsection{Definition}
\blue{Definition 2.1:} Sei $\alpha \in[0,1]$. Ein Konfidenzintervall für $\theta$ mit Niveau $1-\alpha$ ist ein Zufallsintervall $I=[A, B]$, sodass gilt
$$
\forall \theta \in \Theta \quad \mathbb{P}_{\theta}[A \leq \theta \leq B] \geq 1-\alpha
$$
wobei $A, B$ Zufallsvariablen der Form $A=a\left(X_{1}, \ldots, X_{n}\right), B=b\left(X_{1}, \ldots, X_{n}\right)$ mittels 
$a, b: \mathbb{R}^{n} \rightarrow \mathbb{R}$ sind.\\
\textbf{Bemerkung 2.2:} In Eq. (2.1), ist der Paramter $\theta$ deterministisch und nicht zufällig. 
Die stochastischen Elemente sind gerade die Schranken $A=a\left(X_{1}, \ldots, X_{n}\right)$ und 
$B=b\left(X_{1}, \ldots, X_{n}\right)$. \\
\subsection{Verteilungsaussagen}
\blue{Definition 2.3:} Eine stetige Zufallsvariable $X$ heisst $\chi^{2}$-Verteilt mit $m$ Freiheitsgraden falls ihre Dichte gegeben ist durch
$$
f_{X}(y)=\frac{1}{2^{\frac{m}{2}} \Gamma\left(\frac{m}{2}\right)} y^{\frac{m}{2}-1} e^{-\frac{1}{2} y} \text { für } y \geq 0 .
$$
wobei $\Gamma(v):=\int_{0}^{\infty} t^{v-1} e^{-t} d t$ mit $\Gamma(n)=(n-1)$ ! für $v=n \in \mathbb{N}$.
Wir schreiben dann $X \sim \chi_{m}^{2}$. \\
\yellow{Erwartungswert von $X \sim \chi_{m}^{2}$:} Sei $X \sim \chi_{m}^{2}$, dann ist $\mathbb{E}[X] = n$. \\
\yellow{Varianz von $X \sim \chi_{m}^{2}$:} Sei $X \sim \chi_{m}^{2}$, dann ist $\text{Var}[X] = 2n$. \\
\yellow{Satz aus Aufgabe:} Seien die Zufallsvariablen $X_{1}, \ldots, X_{n}$ unabhängig und je $\mathcal{N}\left(\mu, \sigma^{2}\right)$-verteilt unter $\mathbb{P}_{\theta}$, 
wobei $\theta=$ $\left(\mu, \sigma^{2}\right) \in \mathbb{R} \times(0, \infty)$ ein 2-dimensionaler unbekannter Parameter ist. Dann gilt
$\frac{1}{\sigma^{2}} \sum_{i=1}^{n}\left(X_{i}-\bar{X}_{n}\right)^{2} \sim \chi_{n-1}^{2}$-verteilt ist unter $\mathbb{P}_{\theta} .$\\
\textbf{Bemerkung:} Die $\chi^{2}$ Verteilung mit $m$ Freiheitsgraden ist der Spezialfall einer $G a(\alpha, \lambda)$ Verteilung mit $\alpha=\frac{m}{2}$ und $\lambda=\frac{1}{2}$. Für $m=2$ ergibt das eine Exponentialverteilung mit Parameter $\frac{1}{2}$.\\
\yellow{Satz 2.4:} Sind die Zufallsvariablen $X_{1}, \ldots, X_{m}$ u.i.v. $\sim \mathcal{N}(0,1)$, so ist die Summe $Y:=$ $\sum_{i=1}^{m} X_{i}^{2} \sim \chi_{m}^{2}$. \\
\blue{Definition 2.5:} Eine stetige Zufallsvariable $X$ heisst t-verteilt mit m Freiheitsgraden falls ihre Dichte gegeben ist durch
$$
f_{X}(x)=\frac{\Gamma\left(\frac{m+1}{2}\right)}{\sqrt{m \pi} \Gamma\left(\frac{m}{2}\right)}\left(1+\frac{x^{2}}{m}\right)^{-\frac{m+1}{2}} \text { für } x \in \mathbb{R} .
$$
Wir schreiben dann $X \sim t_{m}$.\\
\yellow{Satz 2.6:} Sind $X$ und $Y$ unabhängig mit $X \sim \mathcal{N}(0,1)$ und $Y \sim \chi_{m}^{2}$, so ist der Quotient
$Z:=\frac{X}{\sqrt{\frac{1}{m} Y}}$ $t$-verteilt mit $m$ Freiheitsgraden. \\
\textbf{Schätzer für $\sigma$ und $\mu$:} Wir betrachten folgende Fälle:\\
Wir intressieren uns für \textbf{$\mu$}
\begin{enumerate}
    \item $\sigma^2$ bekannt
    \item $\sigma^2$ unbekannt
\end{enumerate}

Wir intressieren uns für \textbf{$\sigma^2$}
\begin{enumerate}
    \setcounter{enumi}{2}
    \item $\mu$ bekannt
    \item $\mu$ unbekannt
\end{enumerate}

Für $\mathbb{P}[Z \in [q_{-}, q_{+}]] = 1 - \alpha$ gilt:
\begin{enumerate}
    \item $Z = \sqrt{n}\frac{m - \mu}{\sigma} \sim \mathcal{N}\left(0, 1\right)$ wobei $m = \overline{X_n} = \frac{1}{n}\sum_{i = 1}^nX_i: Z \in [-q_{1-\frac{\alpha}{2}}, q_{1-\frac{\alpha}{2}}] \iff
    m - \frac{q_{1-\frac{\alpha}{2}}}{\sqrt{n}}\sigma \leq \mu \leq m +\frac{q_{1-\frac{\alpha}{2}}}{\sqrt{n}}\sigma$
    \item $Z = \sqrt{n}\frac{m - \mu}{S} \sim t_{n - 1}$ wobei $S^2 =  \frac{1}{n - 1}\sum_{i = 1}^n(X_i - \overline{X_n})^2: Z \in [-q_{1-\frac{\alpha}{2}}, q_{1-\frac{\alpha}{2}}] \iff
    m - \frac{q_{1-\frac{\alpha}{2}}}{\sqrt{n}}|S| \leq \mu \leq m +\frac{q_{1-\frac{\alpha}{2}}}{\sqrt{n}}|S|$
    \item $Z = \frac{n}{\sigma^2} \tilde{S^2}\sim \chi^{2}_{n}$ wobei $\tilde{S^2} =  \frac{1}{n}\sum_{i = 1}^n(X_i - \mu)^2: Z \in [q_{\frac{\alpha}{2}}, q_{1-\frac{\alpha}{2}}] \iff
    \frac{n\tilde{S^2}}{q_{1-\frac{\alpha}{2}}} \leq \sigma^2 \leq \frac{n\tilde{S^2}}{q_{\frac{\alpha}{2}}}$
    \item $Z = \frac{n - 1}{\sigma^2}S^2 \sim \chi^{2}_{n - 1}$ wobei $S^2 =  \frac{1}{n - 1}\sum_{i = 1}^n(X_i - \overline{X_n})^2: Z \in [q_{\frac{\alpha}{2}}, q_{1-\frac{\alpha}{2}}] \iff
    \frac{(n - 1)S^2}{q_{1-\frac{\alpha}{2}}} \leq \sigma^2 \leq \frac{(n -1)S^2}{q_{\frac{\alpha}{2}}}$
\end{enumerate}

\yellow{Satz 2.7:} Seien $X_{1}, \ldots, X_{n}$ i.i.d. $\sim \mathcal{N}\left(\mu, \sigma^{2}\right) .$ Dann $\bar{X}_{n}$ und $S^{2}$ sind unabhängig.
\subsection{Approximative Konfidenzintervalle}
Einen allgemeinen\textbf{ approximativen Zugang} liefert der zentrale Grenzwertsatz. Oft ist ein Schätzer $T$ eine Funktion einer Summe $\sum_{i=1}^{n} Y_{i}$, wobei die $Y_{i}$ im Modell $P_{\theta}$ i.i.d. sind; das einfachste Beispiel ist $T=\bar{Y}_{n}=\frac{1}{n} \sum_{i=1}^{n} Y_{i}$. Nach dem zentralen Grenzwertsatz ist dann für grosse $n$
$$
\sum_{i=1}^{n} Y_{i} \quad \text { approximativ normalverteilt unter } \mathbb{P}_{\theta}
$$
mit Parametern $\mu=n \mathbb{E}_{\theta}\left[Y_{i}\right]$ und $\sigma^{2}=n \operatorname{Var}_{\theta}\left[Y_{i}\right]$. 
Das kann man benutzen, um für die Verteilung von $T$ approximative Aussagen zu bekommen und damit gewisse Fragen 
zumindest approximativ zu beantworten. Wir erhalten also $S_{n}^{*}:=\frac{S_{n}- \mu}{\sqrt{n \sigma^2}} \stackrel{\text { Approx }}{\approx} \mathcal{N}(0,1)$ unter $\mathbb{P}_{\theta}$.\\
\subsubsection{Beispiel approximatives Intervall}
Sei $S_n \sim \operatorname{Bin}(n, \theta)$. Dann folgt $S_{n}^{*} =\frac{S_{n}- n \theta}{\sqrt{n \theta(1- \theta)}}$. Also gilt
$\mathbb{P}_{\theta}\left[\left|\frac{S_{n}-n \theta}{\sqrt{n \theta(1-\theta)}}\right| \leq z_{1-\frac{\alpha}{2}}\right]=\mathbb{P}_{\theta}\left[\left|S_{n}^{*}\right| \leq z_{1-\frac{\alpha}{2}}\right] \approx 1-\alpha$.
Wir gehen davon aus, dass $\theta(1-\theta) \approx \frac{1}{4}$ ist und setzen das ein. Dann wollen wir also
$$
\left|S_{n}-n \theta\right| \leq z_{1-\frac{\alpha}{2}} \sqrt{\frac{n}{4}},
$$
und das approximative Konfidenzintervall für $\theta$ ergibt sich als
$$
\left[\bar{S}_{n}-\frac{z_{1-\frac{\alpha}{2}}}{2 \sqrt{n}}, \bar{S}_{n}+\frac{z_{1-\frac{\alpha}{2}}}{2 \sqrt{n}}\right] .
$$
\section{Tests}
\subsection{Null- und Alternativhypothese}
\begin{enumerate}
    \item Nullhypothese $H_{0}: \theta \in \Theta_{0}$
    \item Alternativhypothese $H_{A}: \theta \in \Theta_{A}$
\end{enumerate}
mit $\Theta_{0} \subset \Theta$ und $\Theta_{A} \subset \Theta$, wobei $\Theta_{0} \cap \Theta_{A} = \emptyset$.
Ist keine explizite Alternative spezifiziert, so hat man $\Theta_{A}=\Theta_{0}^{c}=\Theta \backslash \Theta_{0}$. Null- und/oder Alternativhypothese heissen \textbf{einfach}, 
falls $\Theta_{0}$ bzw. $\Theta_{A}$ aus einem einzelnen Wert, $\theta_{0}$ bzw. $\theta_{A}$, bestehen, 
also z.B. $\Theta_{0}=\left\{\theta_{0}\right\}$ ist; sonst heissen sie \textbf{zusammengesetzt}. 
\subsection{Test und Entscheidung}
\blue{Definition 3.1:} Ein Test ist ein Paar $(T, K)$, wobei
\begin{enumerate}
    \item $T$ eine Zufallsvariable der Form $T=t\left(X_{1}, \ldots, X_{n}\right)$ ist, und
    \item $K \subseteq \mathbb{R}$ eine (deterministische) Teilmenge von $\mathbb{R}$ ist.
\end{enumerate}
Die Zufallsvariable $T=t\left(X_{1}, \ldots, X_{n}\right)$ heisst dann Teststatistik, 
und $K$ heisst kritischen Bereich oder Verwerfungsbereich. \\
\textbf{Entscheidungsregel:}
\begin{enumerate}
    \item die Hypothese $H_{0}$ wird verworfen, falls $T(\omega) \in K$,
    \item die Hypothese $H_{0}$ wird nicht verworfen bzw. angenommen, falls $T(\omega) \notin K$.
\end{enumerate}
\textbf{Fehler:}
\begin{enumerate}
    \item Bei einem Fehler 1. Art wird die Nullhypothese zu Unrecht verworfen, d.h. obwohl sie richtig ist. Das passiert für $\theta \in \Theta_{0}$ und $T \in K$; deshalb heisst $\mathbb{P}_{\theta}[T \in K]$ für $\theta \in \Theta_{0}$ die Wahrscheinlichkeit für einen Fehler 1. Art.
    \item Bei einem Fehler 2. Art wird die Nullhypothese zu Unrecht nicht verworfen, d.h. man akzeptiert die Nullhypothese (verwirft sie nicht), obwohl sie falsch ist. Das passiert für $\theta \in \Theta_{A}$ und $T \notin K$, und deshalb heisst $\mathbb{P}_{\theta}[T \notin K]=1-\mathbb{P}_{\theta}[T \in K]$ für $\theta \in \Theta_{A}$ die Wahrscheinlichkeit für einen Fehler 2. Art.
\end{enumerate}
\subsection{Signifikanzniveau und Macht}
\blue{Definition 3.2:} Sei $\alpha \in(0,1)$. Ein Test $(T, K)$ besitzt Signifikanzniveau $\alpha$, falls
$\forall \theta \in \Theta_{0} \quad \mathbb{P}_{\theta}[T \in K] \leq \alpha$. \\
\blue{Definition 3.3:} Die Macht eines Tests $(T, K)$ wird definiert als folgende Funktion
$\beta: \Theta_{A} \rightarrow[0,1], \quad \theta \mapsto \beta(\theta):=\mathbb{P}_{\theta}[T \in K]$.
\subsection{Konstruktion von Tests}
\blue{Definition 3.5:} Für jedes $x_{1}, \ldots, x_{n}$, definieren wir den Likelihood-Quotienten durch
$$
R\left(x_{1}, \ldots, x_{n}\right):=\frac{L\left(x_{1}, \ldots, x_{n} ; \theta_{A}\right)}{L\left(x_{1}, \ldots, x_{n} ; \theta_{0}\right)} \text {. }
$$
Als Konvention setzten wir $R\left(x_{1}, \ldots, x_{n}\right)=+\infty$, falls $L\left(x_{1}, \ldots, x_{n} ; \theta_{0}\right)=0$. Die Idee 
dieses Tests ist, dass man einen einfacheren Test finden kann, der sich änlich verhält wie der Likelihood-Quotienten und den man stattdessen nehmen kann.
Ein Beispiel wäre $T:=\sum_{i=1}^{n} X_{i}=S_{n}$ für $R\left(x_{1}, \ldots, x_{n} ; \theta_{0}, \theta_{A}\right)$ wobei $X_{1}, \ldots, X_{n} \text { i.i.d. } \sim \operatorname{Be}(\theta)$\\
\green{Theorem $3.7$ (Neyman-Pearson-Lemma):} Sei $c \geq 0$. Sei $(T, K)$ ein LikelihoodQuotienten-Test mit Parameter c und Signifikanzniveau $\alpha^{*}:=\mathbb{P}_{\theta_{0}}[T>c]$. Ist $\left(T^{\prime}, K^{\prime}\right)$ ein anderer Test mit Signifikanzniveau $\alpha \leq \alpha^{*}$, so gilt
$$
\mathbb{P}_{\theta_{A}}\left[T^{\prime} \in K^{\prime}\right] \leq \mathbb{P}_{\theta_{A}}[T \in K]
$$\\
\textbf{Bemerkung:} Falls $R \gg 1$, ist $\Theta_{A}$ wahrscheinlicher und falls $R \ll 1$, ist $\Theta_{0}$ wahrscheinlicher.\\
\blue{Definition 3.6:} Sei $c \geq 0$. Der Likelihood-Quotienten-Test mit Parameter $c$ ist ein Test $(T, K)$, wobei Teststatistik und Verwerfungsbereich gegeben sind durch
$$
T=R\left(X_{1}, \ldots, X_{n}\right) \quad \text { und } \quad K=(c, \infty].
$$
\subsection{z-Test}
Normalverteilung, Test für Erwartungswert bei bekannter Varianz: Dieser Test ist unter dem Namen $z$-Test bekannt. Hier sind $X_{1}, \ldots, X_{n}$ i.i.d. $\sim \mathcal{N}\left(\theta, \sigma^{2}\right)$ unter $\mathbb{P}_{\theta}$ mit bekannter Varianz $\sigma^{2}$, und wir wollen die Hypothese $H_{0}: \theta=\theta_{0}$ testen. 
Mögliche Alternativen $H_{A}$ sind $\theta>\theta_{0}$ oder $\theta<\theta_{0}$ (einseitig), oder $\theta \neq \theta_{0}$ (zweiseitig). 
Die Teststatistik hier ist in jedem Fall
$$
T:=\frac{\bar{X}_{n}-\theta_{0}}{\sigma / \sqrt{n}} \sim \mathcal{N}(0,1) \text { unter } \mathbb{P}_{\theta_{0}}.
$$
Wir können die Intervalle folgender massen wählen:
\begin{enumerate}
    \item $\alpha=\mathbb{P}_{\theta_{0}}\left[T \in K_{>}\right]=\mathbb{P}_{\theta_{0}}\left[T>c_{>}\right]=1-\mathbb{P}_{\theta_{0}}\left[T \leq c_{>}\right]=1-\Phi\left(c_{>}\right)$
    \item $\alpha=\mathbb{P}_{\theta_{0}}\left[T< - c_{<}\right]=\Phi\left( - c_{<}\right) = 1 - \Phi\left(c_{<}\right)$ 
    \item $\alpha=\mathbb{P}_{\theta_{0}}\left[T \in K_{\neq}\right]=\mathbb{P}_{\theta_{0}}\left[T<-c_{\neq}\right]+\mathbb{P}_{\theta_{0}}\left[T>c_{\neq}\right]=\Phi\left(-c_{\neq}\right)+1-\Phi\left(c_{\neq}\right)=2\left(1-\Phi\left(c_{\neq}\right)\right)$
\end{enumerate}
Wobei die $c$ Werte in der Tabelle nachgeschaut werden können und es gilt $c_{\alpha}=-c_{1-\alpha}$.
\subsection{Der p-Wert}
\blue{Definition $3.9$ (Geordnete Testsammlung):} Sei $T$ eine Teststatistik. Eine Familie von Tests $\left(T,\left(K_{t}\right)_{t \geq 0}\right)$ heisst geordert bzgl. $\boldsymbol{T}$ falls $K_{t} \subset \mathbb{R}$ und
$$
s \leq t \Longrightarrow K_{s} \supset K_{t}
$$
gilt. \\
\blue{Definition 3.10:} Sei $H_{0}: \theta=\theta_{0}$ eine einfache Nullhypothese. Sei $\left(T, K_{t}\right)_{t \geq 0}$ eine geordnete Familie von Test. Der $\boldsymbol{p}$ - Wert ist definiert als Zufallsvariable
$$
\text { p-Wert }=G(T),
$$
wobei $G: \mathbb{R}_{+} \rightarrow[0,1]$ mittels $G(t)=\mathbb{P}_{\theta_{0}}\left[T \in K_{t}\right]$ definiert ist. \\
\textbf{Anmerkungen:}
\begin{enumerate}
    \item Der P-Wert ist als Funktion einer Teststatistik $T$ selbst eine Zufallsvariable.
    \item Der P-Wert hängt direkt von den anfänglichen Beobachtungen $X_{1}, \ldots, X_{n}$ ab. Somit wird das Wiederholen des Test auch einen neuen (zufälligen) P-Wert generieren.
    \item Der p-Wert liegt stets in $[0,1]$. Sei $T$ stetig ist und $K_{t}=(t, \infty)$, dann kann gezeigt werden, dass der $\mathrm{P}$-Wert unter $\mathbb{P}_{\theta_{0}}$ auf $[0,1]$ gleichverteilt ist.
    \item Der P-Wert liefert uns die Information, welche Tests in unserer Familie $\left(T, K_{t}\right), t \geq 0$ die Nullhypothese $H_{0}$ ablehnen würden.
    \item Für einen P-Wert mit Wert $p$ gilt, dass alle Tests mit Signifikanzniveau $\alpha>p$ die Nullhypothese $H_{0}$ verwerfen würden und alle Tests mit Signifikanzniveau $\alpha \leq p$ die Nullhypothese $H_{0}$ nicht verwerfen würden.
    \item Der P-Wert ist nur von der Nullhypothese abhängig. Die Alternativhypothese spielt keine Rolle in der Definition des P-Werts.
\end{enumerate}
\textbf{Intuition:} $\mathrm{p}$-Wert ist klein $\Longrightarrow H_{0}$ wird wahrscheinlich verworfen.\\
\subsection{Beispiel eines realisierten approximativen p-Wert}
p-Wert $(\omega)=\left.\left.\left.\mathbb{P}_{\theta_{0}}\left[|T|>t_{0}\right]\right|_{t_{0}=T(\omega)} \approx 2 \mathbb{P}_{\theta_{0}}\left[T>t_{0}\right]\right|_{t_{0}=T(\omega)} \approx 2\left(1-\Phi\left(t_{0}\right)\right)\right|_{t_{0}=T(\omega)}$ 
für $T \stackrel{\text { Approx }}{\approx} \mathcal{N}(0,1)$ unter $\mathbb{P}_{\Theta_{0}}$ und $K:=(-\infty,-c) \cup(+c,+\infty)$.
\section{Zusätzliches}
\subsection{t-Test}
Normalverteilung, Test für Erwartungswert bei unbekannter Varianz. Hier sind $X_{1}, \ldots, X_{n}$ i.i.d. $\sim$ $\mathcal{N}\left(\mu, \sigma^{2}\right)$ unter $P_{\vec{\theta}}$, wobei $\vec{\theta}=\left(\mu, \sigma^{2}\right)$. Wir wollen die Hypothese $\mu=\mu_{0}$ testen. Die Teststatistik ist:
$T:=\frac{\bar{X}_{n}-\mu_{0}}{S / \sqrt{n}} \sim t_{n-1} \quad$ unter $P_{\theta_{0}}$
$S^{2}=\frac{1}{n-1} \sum_{i=1}^{n}\left(X_{i}-\bar{X}_{n}\right)^{2}$
Und die Verwerfungsbereiche:
$$
\begin{array}{lll}
c_{<}=t_{n-1, \alpha} & \left(-\infty, -c_{<}\right) & \mu<\mu_{0} \\
c_{>}=t_{n-1,1-\alpha} & \left(c_{>}, \infty\right) & \mu>\mu_{0} \\
c_{\neq}=t_{n-1,1-\frac{\alpha}{2}} & \left(-\infty, -c_{\neq}\right) \cup\left(c_{\neq}, \infty\right) & \mu \neq \mu_{0}
\end{array}
$$
Wobei gilt $t_{m, \alpha}=-t_{m, 1-\alpha}$.\\
\subsection{Gepaarter Zweiproben-Test}
Hier $\operatorname{sind} X_{1}, \ldots, X_{n}$ i.i.d. $\sim \mathcal{N}\left(\mu_{X}, \sigma^{2}\right)$ 
und $Y_{1}, \ldots, Y_{n}$ i.i.d. $\sim \mathcal{N}\left(\mu_{Y}, \sigma^{2}\right)$ 
unter $P_{\theta}$. Insbesondere ist $m=n$ und die Varianz beider Stichproben dieselbe. 
Differenzen $Z_{i}:=X_{I}-Y_{i}$ sind unter $P_{\theta}$ i.i.d. $\mathcal{N}\left(\mu_{X}-\mu_{Y}, 2 \sigma^{2}\right)$. 
Dann analog $z$ und $t$-Test. (Setzt natürliche Paarung von Daten voraus!) Dieser Test wird benutzt wenn man 
ein und dieselbe Stichprobe hast, die man zu zwei unterschiedlichen Zeitpunkten befragt.\\
\subsection{Ungepaarter Zweiproben-Test}
Hier sind unter $P_{\theta}$ die Zufallsvariablen $X_{1}, \ldots, X_{n}$ i.i.d. 
$\sim \mathcal{N}\left(\mu_{X}, \sigma^{2}\right)$ und $Y_{1}, \ldots, Y_{m}$ i.i.d. 
$\sim \mathcal{N}\left(\mu_{Y}, \sigma^{2}\right)$, wobei die Varianz in beiden Fällen dieselbe ist.
Dieser Test wird benutzt wenn man zwei verschiedene Gruppen vergleichen möchte, egal ob sie aus einer oder zwei Stichproben stammen.
\begin{enumerate}
    \item Bei bekannter Varianz:
    $$
    \begin{aligned}
    &H_{0}: \mu_{X}-\mu_{Y}=\mu_{0} \quad\left(z . B . \mu_{0}=0\right) \\
    &T=\frac{\bar{X}_{n}-\bar{Y}_{m}-\left(\mu_{X}-\mu_{Y}\right)}{\sigma \sqrt{\frac{1}{n}+\frac{1}{m}}} \sim \mathcal{N}(0,1)
    \end{aligned}
    $$
    Die kritischen Werte für den Verwerfungsbereich sind wie oben geeignete Quantile der $\mathcal{N}(0,1)$ Verteilung, je nach Alternative. Das ist der ungepaarte Zweistichproben- $z$-Test.
    \item Bei unbekannter Varianz:
    $$
    \begin{aligned}
    S_{X}^{2} &:=\frac{1}{n-1} \sum_{i=1}^{n}\left(X_{i}-\bar{X}_{n}\right)^{2} \\
    S_{Y}^{2} &:=\frac{1}{m-1} \sum_{j=1}^{m}\left(Y_{j}-\bar{Y}_{m}\right)^{2} \\
    S^{2} &:=\frac{1}{m+n-2}\left((n-1) \cdot S_{X}^{2}+(m-1) \cdot S_{Y}^{2}\right) \\
    T &=\frac{\bar{X}_{n}-\bar{Y}_{m}-\left(\mu_{X}-\mu_{Y}\right)}{S \sqrt{\frac{1}{n}+\frac{1}{m}}} \sim t_{n+m-2}
    \end{aligned}
    $$
    unter jedem $P_{\theta}$. Dieser Test heisst ungepaarter Zweistichproben- $t$-Test.
\end{enumerate}
\subsection{Bedingte Verteilung}
\blue{Def. Bedingte Dichte:} $f(x \mid y):=\frac{P(X=x, Y=y)}{P(Y=y)}=\frac{f(x, y)}{f_{Y}(y)}$
\subsection{Integral}
\yellow{Prob. 3.36:} Let be $A = \{(x,y) | a \leq x \leq b, \rho_1(x) \leq y \leq \rho_2(x) \}$. Let $f: A \rightarrow \mathbb{R}$ be continuous. Then $f$ is integrable on $A$ and the following is true
$$
\int_Af(x,y) d(x,y) = \int_{a}^b dx \int_{\rho_1(x)}^{\rho_2(x)}f(x,y)dy.
$$\\
\yellow{Satz $5.30$ (Partielle Integration):} Seien $a<b$ relle Zahlen und $f, g:[a, b] \longrightarrow \mathbb{R}$ 
stetig differenzierbar. Dann gilt: $\int_{a}^{b} f(x) g^{\prime}(x) d x=f(b) g(b)-f(a) 
g(a)-\int_{a}^{b} f^{\prime}(x) g(x) d x$.\\
\yellow{Satz $5.31$ (Substitution):} Sei $a<b, \phi:[a, b] \longrightarrow \mathbb{R}$ stetig differenzierbar, 
$I \subseteq \mathbb{R}$ ein Intervall mit $\phi([a, b]) \subseteq I$ und $f: I \longrightarrow \mathbb{R}$ eine stetige Funktion. Dann gilt:
$\int_{\phi(a)}^{\phi(b)} f(x) d x=\int_{a}^{b} f(\phi(t)) \phi^{\prime}(t) d t$.\\
\yellow{Prob. 3.38:} 
Let $\bar{X} \subset \mathbb{R}^{n}$ and $\bar{Y} \subset \mathbb{R}^{n}$ be compact subsets. Let $\varphi: \bar{X} \rightarrow \bar{Y}$ be a continuous map. We assume that we can write
$$
\bar{X}=X \cup B, \quad \bar{Y}=Y \cup C
$$
where
\begin{enumerate}
        \item the sets $X$ and $Y$ are open
        \item the sets $B$ and $C$ are negligible
        \item the restriction of $\varphi$ to the open set $X$ is a $C^{1}$ bijective map from $X$ to $Y$
\end{enumerate}
In the situation described above, for any continuous function $f$ on $\bar{Y}$, we have
$$
\int_{\bar{X}} f(\varphi(x))\left|\operatorname{det}\left(J_{\varphi}(x)\right)\right| d x=\int_{\bar{Y}} f(y) d y .
$$\\
\textbf{Integrale}
\begin{itemize}
        \item $\int x^{8} d x=\left\{\begin{array}{ll}\frac{x^{s+1}}{s+1}+C & s \neq-1 \\ \ln x+C & (x>0)\end{array}\right.$
        \item $\int e^{x} d x=e^{x}+C$
        \item $\int \sin x d x=-\cos x+C$
        \item $\int \cos x d x=\sin x+C$
        \item $\int \sinh x d x=\cosh x+C$
        \item $\int \cosh x d x=\sinh x+C$
        \item $\int \frac{1}{\sqrt{1-x^{2}}} d x=\arcsin x+C$
        \item $\int \frac{1}{1+x^{2}} d x=\arctan x+C$
        \item $\int \frac{1}{\sqrt{1+x^{2}}} d x=\operatorname{arsinh} x+C$
        \item $\int \frac{1}{\sqrt{x^{2}-1}} d x=\operatorname{arcosh} x+C$.
        \item $\int \sin(x)^2 dx = \frac{x}{2} - \frac{\sin(x) \cdot \cos(x)}{2} + C$
        \item $\int \cos(x)^2 dx = \frac{x}{2} + \frac{\sin(x) \cdot \cos(x)}{2} + C$
        \item $\int \sin(x) \cdot \cos(x) dx = - \frac{\cos(x)^2}{2} + C$
        \item $\int_{0}^{\infty} z^{k-1} e^{-\lambda z} d z=\lambda^{-k}(k-1) !, k \in \mathbb{N}$
\end{itemize}
\subsection{Allgemeines}
\textbf{Mitternachtsformel: } $a x^2 + b x + c = 0 \Longleftrightarrow x_{1,2} = \frac{-b \pm \sqrt{b^2 - 4 a c}}{2 a}$\\
\textbf{pq-Formel: } $x^2 + p x + q = 0 \Longleftrightarrow x_{1,2} = - \frac{p}{2} \pm \sqrt{\left(\frac{p}{2}\right)^2 - q}$
\includegraphics[width = 0.3\textwidth]{unit_circle_angles.png}
\subsection{Summen}
\textbf{Geometrische Reihe:} Sei $q \in \mathbb{C}$ mit $|q|<1 .$ Dann konvergiert 
$\sum_{k=0}^{\infty} q^{k}$ und dessen Wert ist: $\sum_{k=0}^{\infty} q^{k}=\frac{1}{1-q}$. \\
\textbf{allgemeine Formel für geometrische Reihe: } $\sum_{i = 0}^kp^i= \frac{p^{k + 1}}{p - 1} - \frac{1}{p-1}$\\
\textbf{Binomischer Lehrsatz:} $\sum_{k=1}^{n}\left(\begin{array}{l}n \\ k\end{array}\right) a^{n-k} b^{k}=(a+b)^{n}$ \\
\textbf{Summe der Binomialkoeffizienten:} $\sum_{k=0}^{n}\left(\begin{array}{l}n \\ k\end{array}\right)=2^{n}$\\
\textbf{Summe der ersten $n$ Quadratzahlen:} $\sum_{k=1}^{n} k^{2}=\frac{n(n+1)(2 n+1)}{6}$ \\
\textbf{Summe der ersten $n$ Kubikzahlen:} $\sum_{k=1}^{n} k^{3}=\left(\frac{n(n+1)}{2}\right)^{2}$ \\
\textbf{Gausssche Summenformel: }$\sum_{k=1}^{n} k=\frac{n(n+1)}{2}$\\
\textbf{Exponentialfunktion} $\exp (z):=\sum_{n=0}^{\infty} \frac{z^{n}}{n !}$
\subsection{Schnellnotizen}
$\mathbb{P}[M<m, L \leq l]=\mathbb{P}[M<m]-\mathbb{P}[M<m, L>l]$
\newpage
\end{multicols}
\end{document}
